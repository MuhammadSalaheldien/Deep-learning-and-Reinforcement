{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>94</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.225</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.307</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.591</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "748               3                     187              70              22   \n",
       "745              12                     100              84              33   \n",
       "373               2                     105              58              40   \n",
       "79                2                     112              66              22   \n",
       "551               3                      84              68              30   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "748      200  36.4              0.408   36             1  \n",
       "745      105  30.0              0.488   46             0  \n",
       "373       94  34.9              0.225   25             0  \n",
       "79         0  25.0              0.307   24             0  \n",
       "551      106  31.9              0.591   25             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)           # proportions of target classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)           # 200 trees\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)             # predict actual values\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)        # predict probabilities output and it is used for ROC-AUC\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABFDElEQVR4nO3dd3hUZfrG8e9LpISiICBKB2lWULAuaizISlnsq7sWVhDxp6soEroovVtZEBBRV0VRF5EFAYEAoqCASEcCSEnoHZKQ9v7+mNENISGTMvNOuT/XNRczc87MuefNMM88Z04x1lpEREQkeBRzHUBEREROp+IsIiISZFScRUREgoyKs4iISJBRcRYREQkyKs4iIiJBRsVZIpIxJtoY87Ux5qgxZqrrPJHEGNPeGPNdltsnjDF1fXhcbWOMNcac49+E7uT1Go0xrxhj/h3oXBJ4Ks4RwBjzmzEm2fshuMcYM9kYUzbbPDcaY+YbY457C9bXxphLs81zrjHmdWPMDu9zxXtvV8plucYY85wxZq0x5qQxZpcxZqox5gp/vl4f3Q9UASpaax8o7JMZY2KMMZnecTlujNlkjPlHtnmsdxxOeC9HCrtcH3JNNsakepd3yBgz1xjTyDvttA96b769WQuDMeYcY8w+Y8wZB0TwPne6MaZqYTJaa8taa7cW5jnyEgmFXcKLinPkaGutLQs0Aa4Cev4+wRhzAzAH+AqoCtQBfgGW/N7RGGNKAPOAy4A/A+cCNwIHgWtzWeYbwPPAc8D5QANgGtA6v+H98KFaC/jVWptehFkSvWN8LvACMMEY0zDbPI29xaistbZ8fpddQMO9uaoD+4DJZ5n3CHBXltutgMPZZzLGlAHuA44Cfy+qoOFOXw7EVyrOEcZauweYjadI/2448IG19g1r7XFr7SFrbR9gKfCKd57HgJrAPdba9dbaTGvtPmvtAGvtzOzLMcbUB54BHrbWzrfWnrLWJllrP7LWDvXOE2eM6ZjlMdlXd1pjzDPGmM3AZmPMOGPMyGzL+coY86L3elVjzBfGmP3GmG3GmOdyGgNjzKvAy8BfvR1lB2NMMWNMH2PMdm+n+IEx5jzv/L93XR2MMTuA+XmMsfWOySHgyrPNm0s+X7I87l2DccAY09uX57XWJgEfA5efZbYP8fytf/cY8EEO892Hp5D3Bx7P4/VUNMZMN8YcM8b8CFycbbo1xtTzXm9tjPnZO+9OY8wrOTzlE8aYRGPMbmNM1yzPU8wY08MYs8UYc9AY85kx5nzv5EXef494/+Y3eB/zhDFmgzHmsDFmtjGmlvd+Y4x5zTv+R40xq40xOY6b9308xBjzo3fer35fbk7vnbP9ffN6jTks+3pjzPfGmCPGmF+MMTHZcg30Tj9hPGvDKhpjPvKO70/GmNq5Pbc4Zq3VJcwvwG/AHd7r1YE1wBve26WBDODWHB73D2C39/oU4P18LLMzsD2PeeKAjllutwe+y3LbAnPxdN3RwM3ATsB4p1cAkvF0+8WAFXiKbgmgLrAVaJnLsl8B/p3l9hNAvPdxZYEvgQ+902p7s3wAlAGic3i+GGCX93ox4C9AJnBVttdTz4ex8yXLBO+YNAZOAZfk8lyTgYHe62XxFOfFuYyBxVO49wLlvZe93vtstuedh+dLXRUgHbj6LK9nCvCZd+wuBxJy+DvXyzKOV3jH8Erv8u/O9to/8T7XFcB+/vfe7oLnC2V1oCTwDvBJtseek2W5d3vH+RLgHKAP8L13Wks876fygPHOc9FZ3scJ3tdWBvji93HN6b3j4983t9f4SpbnroZnzVUr73i18N6unCVXPJ4vQ+cB64FfgTu8r/cD4D3Xn0+65PL/xnUAXQLwR/YU5xPAce9//HlAee+06t77GuXwuD8Dad7rc4Gh+Vhmb2BpHvPEkXdxvi3LbQPsAG723n4SmO+9fh2wI9vz98ztw4czC9M84P+y3G4IpHk/xH7/wKx7ltcSg6cYH8FTLDOALtnmscAx7zxHgDdzeS5fslTPMv1H4KFcnmsykOJd3h5gOnBxLmNggXrAROApPF+wJnjvs1nmq+l9rU28t2fj/bKXw/KjvNkbZblvcA5/5xy/tACvA695r//+2rM+13DgXe/1DcDtWaZdlMO4ZS3Os4AOWW4XA5Lw/ORxG55Cdj1QzIf38dAsty8FUr2v/Yz3jo9/39xe4x9/M6A73qKeZd7ZwONZcvXOMm0UMCvL7bbAKl//T+sS2ItWa0eOu6215fAUkUbA7xtxHcbzQXtRDo+5CDjgvX4wl3lyk9/5c7Pz9yvW84kyBXjYe9ffgI+812sBVb2r944Yz8ZWvfB0dr6oCmzPcns7ng/LrI/fydklWs/vyOcCb+L5gM/uamttee8lx9XuPmbZk+V6Ep4OLDcjvcu70Fr7F2vtljxexwd4Vmfntkr7UWCDtXaV9/ZHwN+MMcVzmLeyN3vWsduew3wAGGOuM8Ys8P40cRTPF4TsGxxmf67fN0irBfwny99/A54vSbm9B2oBb2SZ/xCeL4DVrLXzgbeBMcBeY8x4Y8y5ueXOIVPxbLmzTs/vey3ra8ye/4Fs7/nmnP7/bm+W68k53D7b+0YcUnGOMNbahXi6qZHe2yeBH4Cctlh+EM+3fIBvgZbGsyGQL+YB1Y0xzc4yz0k8q9V/d2FOkbPd/gS43/vb4HV4ViGC58NsW5bCV95aW85a28rHvIl4Pux+VxPP6tqsH2Y+ncLNWnsKT1dzhTHmbh+Xn98s/rQYzwd8FeC7HKY/BtQ1ni3/9wCj8RSiu3KYdz+e7DWy3FfzLMv+GE93X8Naex4wDk/BzCr7cyV6r+8E7sr2HihlrU0g57/dTuCpbPNHW2u/B7DWvmmtbYpnI8gGQLez5M6eKY3/fbEl2/J9+fvm9hqz5/8wW/4y1rtNh4Q2FefI9DrQwhjTxHu7B/C48ez2VM4YU8EYMxC4AXjVO8+HeD4MvjDGNPJu1FLRGNPLGHNGAbTWbgb+BXxiPLsZlTDGlDLGPGSM6eGdbRVwrzGmtHeDoA55BbfW/oznA38iMNtae8Q76UfgmDGmu/HswxxljLncGHONj2PyCfCCMaaO8exmNhj41BZga25vzlQ8qxFfLsDDizRLfnnXULQF/uK9/gfvhlQX49lCv4n3cjmeovp4Ds+Vgec31Ve8f+dLc5ovi3LAIWttijHmWjxrR7Lr632uy/BsF/Gp9/5xwKAsG3VVNsa0807bj2cNUdb9qccBPb3PgzHmPGPMA97r13i7+OJ4vkSm4OnCc/OIMeZSY0xpPBvJfe597Tnx5e+b22vM6t9AW2NMS+/7vZT3/1r1s+SUEKHiHIGstfvxrK7s6739HZ4NYO4FduNZjXYV0NxbZH/vBu8ANuL5/fkYnoJYCViWy6Ke43+rBo8AW4B7gK+901/D89vcXuB9/reKOi+feLN8nOU1ZeApKE2AbXi6lol4NoTxxSQ8X0AWeR+fAvzTx8ee7TlrGmPaFuBxRZ0lX6y166y163KY9DjwlbV2jbV2z+8XPLvNtTH/2zo6q2fxrD7dg2etzXtnWfT/Af2NMcfxfLH5LId5FuLZ0GkenlX2c7z3v4Gn657jffxSPGtXsJ4t1Qfh2T3wiDHmemvtf4BhwBRjzDFgLf/r/s/F83v7YTz/Hw7iXduUiw+9r20PUArPez83vvx9c3uNf7DW7gTa4fn5Zj+eL8/d0Od6WDDZvhiLiEg+GGPi8GykNdF1Fgkf+oYlIiISZFScRUREgoxWa4uIiAQZdc4iIiJBRsVZREQkyOR5hhRjzCSgDbDPWnvGgd+NMQbPLgyt8BypqL21dmVez1upUiVbu3bt0+47efIkZcr4eowLyQ+NrX9pfP1HY+tfGl//yWlsV6xYccBaWzmvx/py+rLJePZVzekwfuDZL7C+93IdMNb771nVrl2b5cuXn3ZfXFwcMTExPkSS/NLY+pfG1380tv6l8fWfnMbWGJPr4WuzynO1trV2EZ5jzuamHZ7TDVpr7VKgvDGmKI6pLCIiEpGK4sTf1Tj9IO27vPftLoLnFhERybdly5bxySef4HKPpMTExAKvlSiK4pz9oPSQywkCjDGdgE4AVapUIS4u7rTpJ06cOOM+KRoaW//S+PqPxta/wnF858+fz9ChQzHGUKJECScZUlNTKVmyZIHHtiiK8y5OP4NKdXI+gwrW2vHAeIBmzZrZ7N8o9NuH/2hs/Uvj6z8aW/8Kp/G11jJs2DAGDBjATTfdxLRp0zj//JwO9+5fGzduxFrL3r17Czy2RbEr1XTgMeNxPXDUWqtV2iIiEjDp6ek89dRT9OzZk4cffpi5c+c6KcwjRoxgz549XHLJJYV6Hl92pfoEiAEqGWN2Af3wnEgca+04YCae3aji8exK9Y9CJRIREcmH48eP8+CDD/LNN9/Qu3dv+vfvT7FigT2Mh7WWefPm0bFjRypUqFDo58uzOFtrH85jugWeKXQSERGRfNq1axdt2rRh7dq1TJgwgY4dOzrJ8cYbb3DDDTcUSWGGovnNWURECmHJkiVs3LjRybI3btzIli1bnCy7sNLS0hg4cCDHjh1j5syZ3HnnnQHPkJmZyYcffsg///lPoqKiiux5VZxFRBxr164dBw8edB0jJFWvXp3FixfTuHFjJ8v/4IMPuOqqq4q0MIOKs4iIc6mpqXTs2JGXX3454Mv+4YcfuOGGGwK+3KJywQUXULJkyYAvNz09nVGjRhEbG4vnKNZFS8VZRCQIlCtXjho1auQ9YxHbsmWLk+WGum+++Ya7777bL4UZdFYqERERn6WmptKtWzdatGhBw4YN/bYcFWcREREfpKamsnLlSp555hm/r0rXam0RkQBITEwkISEhx2kZGRkBTiP5lZycTGxsLK+++mpADm6i4iwi4mdr166lWbNmnDp1Ktd5dE7l4HXy5Em2bNlCz549A3bUMRVnERE/stbSpUsXoqOj+fTTTznnnDM/dosVK0bz5s0dpJO8HD9+nB49etCvXz8uuOCCgC1XxVlExI+mT5/OvHnzeOONN2jXrp3rOJIPR44c4bfffuPVV1+lUqVKAV22NggTEfGTU6dO0bVrVy655BKefvpp13EkH06ePEmvXr2oWbNmwAszqHMWEfGbN998ky1btvDNN99QvHhx13HERwcOHGDTpk2MHDmS0qVLO8mg4iwiZ0hNTSUzM9N1DMCTJSUlxXWMfNu/fz8DBgygTZs2tGzZ0nUc8VFGRgYDBw5kwIABzgozqDiLSDYTJkzg6aef1u49RaB48eKMGjXKdQzxUWJiIsuWLeO1117z25G/fKXiLCJ/2LdvHy+99BLXXHNN0Gy8tHXrVurWres6RoFcf/31NGjQwHUM8dF7773Hiy++6Lwwg4qziGTRt29fkpKSeO+992jUqJHrOADExcURExPjOoaEsd9++405c+bQu3dv11H+oK21RQSAVatWMWHCBJ599tmgKcwi/matZf78+bRv3951lNOocxaRPw6Ucf755zs5baGICxs3buTLL7+kV69erqOcQcVZRPjyyy9ZuHAhY8eOpUKFCq7jiPjdyZMn2bZtG7Gxsa6j5EjFWSQMpaWl8dJLLzFr1iyf5t+9ezdXXHEFHTt29HMyEfd++eUXpk6dysCBA11HyZWKs0iYOXbsGPfffz9z586ldevWnHvuuXk+pnjx4nTr1i3H4z6LhJPffvsNay39+/d3HeWs9D9RJIzs3LmT1q1bs2HDBt59912eeOIJ15FEgsaPP/7IzJkz6devX1DsLnU2Ks4iYWLVqlW0bt2aEydOMHPmTFq0aOE6kkjQ+Omnn7jwwgtDojCDdqUSCQuzZs3ipptuIioqiu+++06FWSSL5cuXM3/+fGrUqBEShRlUnEVC3jvvvEPbtm2pV68eS5cu5YorrnAdSSRofPvtt1StWpXu3buHTGEGFWeRkDZy5Eg6d+5My5YtWbRoEVWrVnUdSSRobNq0ifXr14fk/wsVZ5EQ9vHHH3Pttdfy1VdfUa5cOddxRILGV199hTGG5557znWUAlFxFglxVapU0S5QIlns27eP/fv3h/RJR/Q/WkREwsaUKVOoXbt2yB9QR52ziIiEhePHjxMVFcX111/vOkqhqXMWEZGQN2nSJKpVq8YDDzzgOkqRUHEWCSFHjx5l4sSJnDx5EvAcE7t69eqOU4m4deDAAerUqcOtt97qOkqRUXEWCSFdunRh8uTJp92ncy9LJBszZgy1a9emdevWrqMUKRVnkRDx008/MXnyZLp168bQoUP/uL9YMW06IpFp7dq13HHHHTRs2NB1lCKn/9UiIcBaS5cuXahSpQp9+vShWLFif1xEItFrr73Gnj17wrIwgzpnkZAwZcoUvv/+eyZOnOjTKSBFwpW1ljlz5vDEE09w3nnnuY7jN/raLRLkkpKSiI2N5aqrrqJ9+/au44g49a9//YuyZcuGdWEGdc4iQW/48OHs2rWLjz/+mKioKNdxRJyw1vLee+/x9NNPR8TPOeH/CkVC3IQJE2jTpg033XST6ygiznzyySc0adIkIgozqHMWCXqpqanUrFnTdQwRJzIyMhg+fDixsbERteYoMr6CiIhIyLHWMm/ePNq1axdRhRlUnEVEJAilpaURGxvLn/70Jy699FLXcQJOq7VFRCSopKamsmbNGjp37kyZMmVcx3FCxVmkEE6dOkVCQgKJiYls3brVL8vIyMjwy/OKBKOUlBRiY2Pp06cPF1xwges4zqg4ixRQamoq11xzDWvWrPH7skqVKuX3ZYi4lpSUxJYtW4iNjY3owgwqziIF9uabb7JmzRoGDRrE8ePHueSSS/yyHGMMLVu29MtziwSLkydP0r17d/r06cOFF17oOo5zKs4iBbB371769+9P69at6dWrF3FxccTExLiOJRKSjh07xtatW+nXrx+VK1d2HScoaGttkQLo06cPycnJjBo1ynUUkZCWkpJCz549qVGjhgpzFuqcRfLp559/5t133+WFF14I2zPiiATCoUOHWLNmDSNHjiQ6Otp1nKCizlkkH6y1PP/881SsWJG+ffu6jiMSsjIzMxk0aBBNmjRRYc6BOmeRfJg6dSqLFy9m3LhxlC9f3nUckZC0Z88eFi1axMiRIzHGuI4TlNQ5i/goOTmZbt26ceWVV9KxY0fXcURC1vvvv0/r1q1VmM9CnbOIj0aOHMmOHTt4//33I+44vyJFYceOHUyfPp3u3bu7jhL01DmL+CAhIYGhQ4dy3333aZcpkQLIzMxkwYIFPPnkk66jhAR1ziI+6NGjBxkZGYwYMcJ1FJGQs3nzZj7++GP69evnOkrIUOcskoelS5fy73//mxdffJE6deq4jiMSUo4fP85vv/1G7969XUcJKSrOInl46aWXuOiii+jZs6frKCIhZe3atQwaNIg77riDc87Ritr8UHEWycOaNWu4//77KVeunOsoIiFj69atZGZmMnjwYG2VXQAqziI+0NbZIr5bsWIF7733HpdffjnFiqnMFIRGTUREiszy5cupVKkS/fv3V2EuBI2ciIgUiV9++YXZs2dTs2ZNrcouJBVnEREptAULFlC+fHl69eqlwlwEVJxF8mCtdR1BJKht27aNn3/+mVq1aqkwFxEVZ5GzmDdvHsePH9f+zSK5+O9//8uJEyd48cUXXUcJKyrOIrlIT0+nS5cu1KlTh06dOrmOIxJ0Dh8+zK5du7jiiitcRwk72itcJBfjx49n7dq1fPHFF5QqVcp1HJGgMnXqVC644AKeeuop11HCkjpnkRwcOnSIl19+mZiYGO655x7XcUSCSlJSEgC33HKL4yThS52zSA5effVVDh8+zOuvv64NXESy+OCDD6hQoQIPPPCA6yhhTcVZJJsNGzYwZswYnnzySRo3buw6jkjQ2L9/P7Vq1VLHHAAqziLZfP7552RkZDBgwADXUUSCxjvvvMOFF15Iu3btXEeJCCrOItlkZGQAULlyZcdJRILD6tWruf3226lXr57rKBFDG4SJiEiu3n77bXbv3q3CHGDqnEVE5AzWWmbNmsXjjz+u06U6oM5ZRETOMHHiRMqVK6fC7Ig6ZxER+YO1lokTJ9KhQwed8tEhjbxINvHx8ZQsWdJ1DBEnvvzyS5o0aaLC7Jg6Z5EsVqxYwccff0zXrl1dRxEJqMzMTAYPHkz37t0pXry46zgRz6evRsaYPxtjNhlj4o0xPXKYfp4x5mtjzC/GmHXGmH8UfVQR/7LW8vzzz1OpUiX69OnjOo5IwFhrWbRoEe3atVNhDhJ5FmdjTBQwBrgLuBR42BhzabbZngHWW2sbAzHAKGNMiSLOKuJXn332GUuWLGHw4MGcd955ruOIBERGRgaxsbFcddVVOrtUEPGlc74WiLfWbrXWpgJTgOyHiLFAOeM5CHFZ4BCQXqRJRfwoKSmJ2NhYmjRpwj/+oRU/EhlSU1PZtm0bnTp10hfSIOPLb87VgJ1Zbu8Crss2z9vAdCARKAf81Vqbmf2JjDGdgE4AVapUIS4u7rTpJ06cOOM+KRqRMrYpKSmkp+f/e+HUqVPZsWMHL774IosXL8734yNlfF3Q2PpHamoq77zzDn/5y19ISEggISHBdaSwU6j3rrX2rBfgAWBiltuPAm9lm+d+4DXAAPWAbcC5Z3vepk2b2uwWLFhwxn1SNMJ9bBMTE+3jjz9ujTEWz5qcfF8eeOCBAi8/3MfXJY1t0UtOTrZr1qyx27dv1/j6UU5jCyy3edRda61PnfMuoEaW29XxdMhZ/QMY6l1wvDFmG9AI+NHnbwkiBZCSksLrr7/OoEGDSE1N5dlnn6VOnTr5fp6SJUvy97//3Q8JRYJLUlIS3bt3p0ePHlSrVo2tW7e6jiQ58KU4/wTUN8bUARKAh4C/ZZtnB3A7sNgYUwVoCOgvLn5jreWrr76ia9eubN26lXbt2jFy5Egd/1fkLE6cOMGvv/7Kyy+/rBO7BLk8Nwiz1qYDzwKzgQ3AZ9badcaYzsaYzt7ZBgA3GmPWAPOA7tbaA/4KLZFt7dq1tGjRgnvuuYdSpUoxZ84cpk2bpsIschZpaWnExsZSvXp1FeYQ4NNBSKy1M4GZ2e4bl+V6InBn0UYTOd2hQ4fo168fY8eOpVy5crz55pt07txZ+2WK5OHw4cMsX76c1157TUe/CxE6PpsEvfT0dMaMGUP9+vX517/+RadOndi8eTP//Oc/VZhF8mCtZciQIVxzzTUqzCFEh++UoPPVV1/x/PPPk5np2RsvKSmJgwcPcuutt/L6669z5ZVXOk4oEhr27dvH3LlzGTZsGJ7DUEioUHGWoLNs2TJ27NhB+/btATDG0Lp1a+655x59wIjkw4cffshTTz2l/zchSMVZgtI555zDpEmTXMcQCUkJCQl89tlnOoFLCNNvziIiYSQzM5OFCxfy9NNPu44ihaDOWUQkTGzdupVJkyYxcOBA11GkkNQ5i4iEgaNHj7J9+3b69evnOooUARVnCTq/b6UtIr7ZsGEDAwcOJCYmRrsXhgkVZwkqKSkpfPrpp1x++eWuo4iEhC1btpCRkcHQoUO1VXYYUXGWoDJ69Gh+++03Ro0a5TqKSNBbvXo17777LpdeeilRUVGu40gRUnGWoJGYmMjgwYO59957ufXWW13HEQlqK1asoFy5cgwcOJBixfRRHm70F5Wg0bNnT9LS0hgxYoTrKCJBbf369cycOZPatWurMIcp/VUlKCxbtowPPviAF198kbp167qOIxK0Fi1aRIkSJejTp49+Yw5jKs7inLWWLl26cOGFF9KrVy/XcUSCVmJiIsuWLePiiy9WYQ5zKs7i3MGDB1m6dCnPPfcc5cqVcx1HJCjNnj2b3bt3061bNxXmCKDiLM5ZawE499xzHScRCU4nTpxg27ZtNG3a1HUUCRAdvlNEJIj95z//oWzZsnTu3Nl1FAkgdc4iIkEqOTmZjIwMWrRo4TqKBJg6ZxGRIPTRRx8RHR3N/fff7zqKOKDiLCISZPbu3UutWrVo3ry56yjiiIqziEgQmThxIuXLl1fHHOFUnEVEgsTPP//M7bffTp06dVxHEce0QZiISBB45513SExMVGEWQJ2ziIhz06dP55FHHqFMmTKuo0iQUOcsIuLQ5MmTKVu2rAqznEads4iIA9Zaxo8fT8eOHXUuZjmDOmdxbufOnQCUKFHCcRKRwJkxYwZXXnmlCrPkSJ2zOGWtpUePHlSoUIF7773XdRwRv8vMzGTw4MG89NJLlCpVynUcCVIqzuLU119/zdy5c3njjTeoWLGi6zgifmWtZenSpbRp00aFWc5Kq7XFmVOnTtG1a1cuueQSnn76addxRPwqPT2d7t2706BBA5o0aeI6jgQ5dc7izJtvvkl8fDzffPMNxYsXdx1HxG/S0tLYuHEjTzzxBJUqVXIdR0KAOmdxYu/evQwYMIDWrVvTsmVL13FE/CY1NZXY2FjOO+88GjVq5DqOhAh1zuJE7969SU5OZvTo0a6jiPjNqVOniI+P5/nnn6dmzZqu40gIUecsAbdy5UomTZrEc889R4MGDVzHEfGLlJQUunXrRrly5ahdu7brOBJi1DlLQFlref7556lYsSJ9+/Z1HUfEL06ePMmGDRvo27cvlStXdh1HQpA6ZwmoqVOn8t133zFo0CDKly/vOo5IkcvIyKBHjx7UqFFDhVkKTJ2zBExycjLdunWjcePGdOjQwXUckSJ39OhRvv/+e0aNGqUj3kmhqHOWgBk5ciQ7duzg9ddf1yELJSyNGDGC6667ToVZCk2dc4SaOHEiY8aMCegyN2zYwH333UdMTExAlyvibwcOHGDGjBkMHDjQdRQJEyrOEWjr1q0888wzNGjQgLp16wZsuVdccQVDhgwJ2PJEAuXjjz+mffv2rmNIGFFxjkDdunWjePHizJ49m6pVq7qOIxKydu/ezYcffkhsbKzrKBJm9JtzhJk/fz5ffvklvXr1UmEWKYSMjAwWL17Ms88+6zqKhCEV5wiSnp5Oly5dqF27Ni+++KLrOCIh67fffqNXr148+OCDlC5d2nUcCUNarR1BJk6cyJo1a5g6dapOVydSQIcPH2bHjh0MGDDAdRQJYyrOYWTfvn28/PLLJCcnnzFtz549/PTTT9x8883cd999DtKJhL5NmzYxfvx4hg8frt0Bxa9UnMNIXFwc77zzDlWrVj1jP8uUlBRq1arFmDFjMMY4SigSuuLj40lPT2fYsGEqzOJ3Ks5haO7cuVx66aWn3RcXF6f9i0UKaN26dfz73/9m4MCBKswSENogTETkLH7++WdKlSrFoEGDVJglYFScRURyER8fz7Rp06hbty7FiunjUgJH7zYRkRwsWbKEtLQ0XnnlFW2nIQGn4iwiks3+/ftZvHgxjRo1UmEWJ7RBmIhIFt9++y2lS5emR48erqNIBFPnLCLilZyczObNm7nxxhtdR5EIp85ZRASYPn06xYoV4+mnn3YdRUSds4hIcnIyqamptGnTxnUUEUCds4hEuClTpgDw0EMPOU4i8j8qziEmJSWFH374gfT09DOmrV692kEikdC1e/duatWqxQ033OA6ishpVJxDyN69e2nbti0//fTTWecrV65cgBKJhK733nuP6OhodcwSlFScQ8SGDRto1aoVe/fu5b333qN+/fo5znf++edTo0aNAKcTCS3Lly/n9ttvp2bNmq6jiORIxTkELFy4kLvvvpuSJUuycOFCrrnmGteRRELWpEmTqFixIs2aNXMdRSRXKs5B7qOPPuIf//gH9erVY+bMmdSuXdt1JJGQNW3aNB566CFKly7tOorIWWlXqiBlrWXgwIE88sgj/OlPf2LJkiUqzCKFMGXKFMqUKaPCLCFBnXMQSktLo3PnzkyaNIlHH32UiRMnUqJECdexREKStZZ33nmHjh07cs45+siT0KDOOQiNGjWKSZMm8fLLL/P++++rMIsUwpw5c7j88stVmCWkqDgHocTERCpUqMCrr76qM+KIFJC1lkGDBtG8eXOaN2/uOo5IvuirpIiEnczMTFauXMmf//xnypQp4zqOSL6pcxaRsJKRkUGvXr2oVq0aTZs2dR1HpEDUOYtI2EhPT2fz5s08+uijXHTRRa7jiBSYOmcRCQtpaWl0796dkiVLctlll7mOI1Io6pwdGTZsGKNHj85x2rFjx7Qvpkg+pKamsnnzZp555hnq1q3rOo5Ioak4O/L7maUefPDBHKfrtzIR36SmptKtWzdeeOEFHahHwoaKs0M1atRg7NixrmOIhKzk5GRWr15N3759qVSpkus4IkVGvzmLSEiy1tKzZ09q1qypwixhR52ziISc48ePs2DBAkaMGEHx4sVdxxEpcuqcRSTkjBo1ihtvvFGFWcKWOmc/euutt/jqq69ynPbLL79QrVq1ACcSCW2HDh3iiy++4JVXXnEdRcSvfOqcjTF/NsZsMsbEG2N65DJPjDFmlTFmnTFmYdHGDE2TJ09m5cqVpKSknHFp2LAhf/vb31xHFAkpn376aa57OIiEkzw7Z2NMFDAGaAHsAn4yxky31q7PMk954F/An621O4wxF/gpb8j505/+xNdff+06hkhI27t3LxMmTKBPnz6uo4gEhC+d87VAvLV2q7U2FZgCtMs2z9+AL621OwCstfuKNqaIRKqMjAyWLFnCCy+84DqKSMD4UpyrATuz3N7lvS+rBkAFY0ycMWaFMeaxogooIpFr586dvPPOO9xzzz06u5REFF82CMvphMI2h+dpCtwORAM/GGOWWmt/Pe2JjOkEdAKoUqUKcXFxpz3JiRMnzrgvlB0/fpyDBw8GxWsKt7ENNhrfonf06FF27drFQw89xMKF2ozFX/Te9Z/CjK0vxXkXUCPL7epAYg7zHLDWngROGmMWAY2B04qztXY8MB6gWbNmNiYm5rQniYuLI/t9oeTAgQOMHj2alJQUAI4cOULDhg2D4jWF+tgGO41v0YqPj2fatGmMHDmS7777TmPrR3rv+k9hxtaX4vwTUN8YUwdIAB7C8xtzVl8BbxtjzgFKANcBrxUoUQibPXs2Q4YMoUyZMhQr5vnFoFmzZo5TiYSWLVu2cOrUKUaMGME552hvT4lMeb7zrbXpxphngdlAFDDJWrvOGNPZO32ctXaDMeYbYDWQCUy01q71Z/BgZK1nbf+qVauoV6+e4zQioWfTpk28++67DB48WIVZIppP735r7UxgZrb7xmW7PQIYUXTRRCSS/PLLL0RHRzNkyBCioqJcxxFxSofvFBHnduzYwdSpU6lXr54Kswg6fKeIOLZs2TKio6MZMGAAxuS0c4hI5FHnLCLOHDlyhPnz53PFFVeoMItkoc5ZRJz4ff/Pnj17ug0iEoTUOYtIwKWmprJx40btXyuSC3XOIhJQM2fOJCUlhc6dO7uOIhK01DmLSMAkJydz6tQp7r33XtdRRIKaOmcRCYjPP/+c5ORkHn30UddRRIKeirOI+N2uXbuoWbMm1157resoIiFBxVlE/Orf//43xhj+/ve/u44iEjJUnEXEb5YtW8att95KtWrZTwEvImejDcJExC8+/PBDEhISVJhFCkCds4gUuS+++IL777+f6Oho11FEQpI6ZxEpUl9++SVlypRRYRYpBHXOIlIkrLWMHTuWjh07UqJECddxREKaOuciYq1l2bJlADpJvESkhQsXctlll6kwixQBFecikJqayhNPPMHbb79N+/btqVWrlutIIgFjrWXQoEE0adKEW265xXUckbCg4lxIR44coVWrVkyePJlXXnmFSZMm6dR3EjGstaxevZoWLVpQvnx513FEwoaKcyHs2LGD5s2bs3DhQiZPnky/fv1UmCViZGZm0qdPHypUqKAjf4kUMf04WkArV66kdevWJCcnM3v2bG677TbXkUQCJiMjg61bt/LXv/6VmjVruo4jEnbUORfAjBkzuPnmmylRogRLlixRYZaIkp6eTo8ePbDWcuWVV7qOIxKWVJzzad68ebRr145GjRqxbNkyLrvsMteRRAImLS2NTZs20blzZxo0aOA6jkjYUnHOp2XLlpGZmcm3337LhRde6DqOSMCkp6cTGxtLqVKluPjii13HEQlr+s25gEqXLu06gkjApKSksGLFCvr27cv555/vOo5I2FPnLCJnZa2ld+/e1KpVS4VZJEDUOYtIrk6cOMGcOXMYNmyYjnwnEkDqnEUkV2+88QbNmzdXYRYJMP2PE5EzHDlyhI8//pjevXu7jiISkdQ5i8gZPv/8cx5++GHXMUQiljpnEfnD/v37GTNmDK+88orrKCIRTZ2ziACeA4wsXbqUrl27uo4iEvFUnEWEhIQEunXrRps2bShXrpzrOCIRT8VZJMLt37+fhIQEhgwZorOqiQQJFWeRCLZt2zYGDhxIkyZNiI6Odh1HRLy0QZhIhNqyZQunTp1ixIgRlChRwnUcEclCnbNIBNqyZQtjx46lQYMGKswiQUids0iEWbt2LVFRUQwbNoyoqCjXcUQkB+qcRSLI7t27+fjjj2nYsKEKs0gQU+csEiGWL18OwKBBg7RVtkiQU3H2wc8//8yuXbsA2LBhg+M0Ivl38uRJZs+eTa9evVSYRUKAinMeUlNTue6660hLS/vjvrJly2qVoISMxYsXk5SUpJNYiIQQ/each4yMDNLS0nj22WdZvnw5y5cvZ+PGjSrOEhLS09NZv349d955p+soIpIP6px9VL16dZo2beo6hojPZs+ezaFDh3jqqadcRxGRfFLnLBKGkpKSSElJ0WkfRUKUOmeRMDNt2jQOHTrEE0884TqKiBSQirNIGNm+fTs1atTg7rvvdh1FRApBxVkkTHzyySekpqby+OOPu44iIoWk4iwSBpYsWUJMTAwXXXSR6ygiUgS0QZhIiJsyZQoJCQkqzCJhRJ2zSAj7/PPPufvuuylVqpTrKCJShNQ5i4SoGTNmULJkSRVmkTCkzlkkBI0dO5b27dsTHR3tOoqI+IE65zycOHECQCcLkKDx/fff07BhQxVmkTCm4pyHIUOGYIyhRYsWrqNIhLPWMmTIEOrXr89tt93mOo6I+JGK81ls2rSJt956iw4dOnDVVVe5jiMRzFrLxo0bueWWW6hcubLrOCLiZyrOZ9G1a1eio6MZOHCg6ygSwTIzM+nXrx/FixfnxhtvdB1HRAJAG4Tl4ptvvuG///0vI0aMoEqVKq7jSITKzMxk27Zt3HvvvdSrV891HBEJEHXOOUhLS+OFF16gXr16PPfcc67jSITKyMigZ8+enDp1iiZNmriOIyIBpM45B++++y4bN25k+vTplChRwnUciUDp6els2rSJTp06cfHFF7uOIyIBps45B6tWraJSpUq0adPGdRSJQJmZmcTGxlKiRAkVZpEIpc45F1FRUdq3WQLu1KlTLFu2jJdffpny5cu7jiMijqhzFgki/fr1o3bt2irMIhFOnbNIEEhKSmLGjBkMGjSIqKgo13FExDF1ziJBYMyYMdx8880qzCICqHMWcerYsWO89957dOvWzXUUEQki6pxFHLHW8p///IdHHnnEdRQRCTIqziIOHDx4kN69e/P4449TsWJF13FEJMioOIsE2KlTp/jxxx/p0aOH6ygiEqRUnEUCaPfu3bz00kvceeednHvuua7jiEiQUnEWCZB9+/aRkJDAsGHDtFW2iJyVirNIAGzfvp2BAwdy+eWXU7p0addxRCTIaVcqET/btm0bSUlJjBgxgpIlS7qOIyIhQJ2ziB9t376dt956iwYNGqgwi4jP1DmL+MmGDRvIyMhg+PDhnHOO/quJiO/UOYv4wYEDB5g8eTKXXHKJCrOI5Js+NUSK2M8//0xycjJDhw7VaUdFpEB86pyNMX82xmwyxsQbY3I9coIx5hpjTIYx5v6iiygSOlJSUpg5cybXX3+9CrOIFFienbMxJgoYA7QAdgE/GWOmW2vX5zDfMGC2P4KKBLvvv//+j8NyiogUhi+d87VAvLV2q7U2FZgCtMthvn8CXwD7ijCfSEjIyMhg7dq1tGnTxnUUEQkDvhTnasDOLLd3ee/7gzGmGnAPMK7ooomEhnnz5jF37lw6deqkVdkiUiR82SAsp08bm+3260B3a23G2T6cjDGdgE4AVapUIS4u7rTpJ06cOOM+FxITE0lNTQ2KLEUlWMY23CQnJ7Nq1SqaN2+u8fUTvXf9S+PrP4UZW1+K8y6gRpbb1YHEbPM0A6Z4C3MloJUxJt1aOy3rTNba8cB4gGbNmtmYmJjTniQuLo7s97kwZcoUSpQoERRZikqwjG04mTFjBomJifTs2VPj60caW//S+PpPYcbWl+L8E1DfGFMHSAAeAv6WdQZrbZ3frxtjJgMzshdmkXCydetWqlevrt+YRcQv8izO1tp0Y8yzeLbCjgImWWvXGWM6e6frd2aJKFOnTuXYsWN06NDBdRQRCVM+HYTEWjsTmJntvhyLsrW2feFjiQSnRYsWccstt3DBBRe4jiIiYUyH7xTx0ZdffkliYqIKs4j4nQ7fKeKDqVOn0qZNG6Kjo11HEZEIoM5ZJA9z586lePHiKswiEjDqnEXOYuzYsTz66KOULVvWdRQRiSARU5y3bNnCX/7yF5KTk/Ocd//+/ZQpUyYAqSSYrVixgosvvliFWUQCLmKK86effsr69et55JFHfDrE4vXXXx+AVBKMrLWMGDGCRx55hKZNm7qOIyIRKGKK88yZM2natCkffvih6ygSxKy1bNmyhRtuuIGqVau6jiMiESoiNgg7dOgQP/zwA61atXIdRYKYtZZXX32VtLQ0brrpJtdxRCSCRUTnPGfOHDIzM1WcJVeZmZls376dv/zlL1xyySWu44hIhIuIznnWrFlUrFiRa665xnUUCUKZmZn07t2b48ePc/XVV7uOIyIS/p1zZmYms2bNomXLlkRFRbmOI0EmIyOD9evX8+STT1K3bl3XcUREgAjonFesWMH+/fu1SlvOYK2lR48eFC9eXIVZRIJK2HfOM2fOxBhDy5YtXUeRIJKamsrixYvp06cP5513nus4IiKnCfvOedasWVx77bVUqlTJdRQJIv3796du3boqzCISlMK6OO/fv58ff/xRq7TlD8nJyXz00Uf079+fOnXquI4jIpKjsC7Os2fPxlrLXXfd5TqKBIlx48YRExNDsWJh/dYXkRAX1r85z5o1i8qVK+sQjMLx48cZP348Xbt2dR1FRCRPYd0+rF69muuvv15dUoSz1vL111/z2GOPuY4iIuKTsK9axYsXdx1BHDp8+DDdu3fn4YcfpnLlyq7jiIj4JOyLs0SulJQUVqxYQa9evXw6E5mISLBQcZawtHfvXrp27cott9xC+fLlXccREckXFWcJO/v27SMhIYHhw4frZw0RCUlhtbV2eno633zzDcnJyQAcPXrUcSIJtF27djFs2DCGDx9OdHS06zgiIgUSVsW5R48ejBo16rT7dNjOyLF9+3ZOnDjBiBEjKFWqlOs4IiIFFjbF+ddff+WNN97gkUceoUePHn/cX79+fYepJFASExN5/fXXGTZsGCVKlHAdR0SkUMKmOHft2pXo6GhGjhxJlSpVXMeRAPr1119JTk7Wb8wiEjbCYoOw2bNnM2PGDPr27avCHGGOHj3KxIkTueyyy1SYRSRshHznnJaWxgsvvEC9evV47rnnXMeRAFq9ejWHDh1i2LBh2o9ZRMJKyHfO48aNY8OGDYwaNYqSJUu6jiMBkpaWxowZM7j55ptVmEUk7IR85zx8+HBuvfVW2rZt6zqKBMiPP/7Izp076dWrl+soIiJ+EfKd87Fjx2jcuLG6pwiRmZnJ6tWruffee11HERHxm5DvnCVyxMXFsXnzZp588knXUURE/CrkO2eJDMeOHSM5OZmOHTu6jiIi4nfqnCXozZo1iy1btvDss8+6jiIiEhAqzhLUNm/eTPXq1bnrrrtcRxERCRit1pagNW3aNOLi4rjiiitcRxERCSh1zhKU4uLiaN68OZUqVXIdRUQk4NQ5S9D5+uuv2bVrlwqziEQsdc4SVD799FPatm1L6dKlXUcREXFGnbMEjYULF3LOOeeoMItIxFPnLEFh3Lhx/PWvf6VChQquo4iIOKfOWZxbs2YNNWvWVGEWEfFScRanRo0aRdmyZWnVqpXrKCIiQUOrtcUJay07duygadOm1KlTx3UcEZGgos5ZAs5ay6BBgzhy5AgxMTGu44iIBB0VZwkoay3bt2/nrrvuonHjxq7jiIgEJRVnCZjMzEz69u3L4cOHadq0qes4IiJBKyh/c/7hhx+YOHGiT/MmJSX5OY0UhYyMDNauXUuHDh30G7OISB6CsjhPmDCB999/n6pVq+Y5b9WqVbn++usDkEoKylpL7969efTRR1WYRUR8EJTFGaBatWrs2LHDdQwppLS0NBYsWEDv3r0pV66c6zgiIiFBvzmLXw0ePJi6deuqMIuI5EPQds4S2lJSUvj000/p27cvxYrpO6CISH7oU1P8YtKkSdx2220qzCIiBaDOWYrUyZMnefvtt+nevbvrKCIiIUttjRQZay0zZ86kffv2rqOIiIQ0FWcpEkeOHKFr167cd999VKlSxXUcEZGQpuIshZacnMwvv/xCnz599BuziEgR0CepFMqBAwd46aWXuO666zj//PNdxxERCQvaIEwKbP/+/SQkJDB06FBKlSrlOo6ISNhQ5ywFsnv3bl599VXq16+vA4yIiBQxdc6Sbzt37uTIkSOMGDGC6Oho13FERMKOOmfJl3379jFy5Ejq16+vwiwi4ifqnMVn8fHxHD16lBEjRlCiRAnXcUREwpY6Z/HJyZMnGT9+PFdeeaUKs4iIn6lzljytW7eOhIQEhg0bhjHGdRwRkbCnzlnOKiMjg+nTp3P77berMIuIBIg6Z8nVihUr2LRpEz179nQdRUQkoqhzlhxlZGSwZs0aHn74YddRREQijjpnOcN3333H6tWr+b//+z/XUUREIpI6ZznN0aNHSUpK4umnn3YdRUQkYqlzlj/MnTuXdevW0aVLF9dRREQimoqzALBx40aqVatGixYtXEcREYl4Wq0tzJgxgwULFnDppZe6jiIiIqhzjngLFizghhtuoE2bNq6jiIiIlzrnCPbNN9+wfft2Klas6DqKiIhkoc45Qn322We0atWKsmXLuo4iIiLZqHOOQEuXLgVQYRYRCVI+FWdjzJ+NMZuMMfHGmB45TP+7MWa19/K9MaZx0UeVojBhwgTq1q3Lgw8+6DqKiIjkIs/ibIyJAsYAdwGXAg8bY7Jv1rsNuMVaeyUwABhf1EGl8H799VcuvPBCLrjgAtdRRETkLHzpnK8F4q21W621qcAUoF3WGay131trD3tvLgWqF21MKazPP/8cay1t27Z1HUVERPLgywZh1YCdWW7vAq47y/wdgFk5TTDGdAI6AVSpUoW4uLjTpp84cYK4uDh2797NqVOnzpgu+Wet5eDBg1x00UXs3r2b3bt3u44Uln5/70rR09j6l8bXfwoztr4U55xO4mtznNGYW/EU5+Y5TbfWjse7yrtZs2Y2JibmtOlxcXHExMTwwQcfULJkSbJPl/yx1jJ06FBatGhBpUqVNJ5+9Pt7V4qexta/NL7+U5ix9WW19i6gRpbb1YHE7DMZY64EJgLtrLUHC5RGioy1lh07dtCiRQuaNWvmOo6IiOSDL8X5J6C+MaaOMaYE8BAwPesMxpiawJfAo9baX4s+puSHtZZ+/fqxb98+FWYRkRCU52pta226MeZZYDYQBUyy1q4zxnT2Th8HvAxUBP5ljAFIt9aqKjiQmZnJL7/8QocOHahVq5brOCIiUgA+HSHMWjsTmJntvnFZrncEOhZtNCmIfv368eCDD6owi4iEMB2+M0ykp6czZ84cevToQZkyZVzHERGRQtDhO8PE8OHDqVevngqziEgYUOcc4k6dOsWHH35Iz5498f7eLyIiIU6dc4h7//33adGihQqziEgYCYrO2VrLzJkzWbJkCTt37iQ+Pt51pKCXlJTE6NGj6d27twqziEiYCYriHB8fT5s2bU677+qrr3aUJvhZa5kzZw4dOnRQYRYRCUNBsVr71KlTADz33HPEx8cTHx/PokWLHKcKTseOHeOFF16gbdu2XHTRRa7jiIiIHwRF5/y7888/n4svvth1jKB18uRJ1qxZQ58+fYiKinIdR0RE/CQoOmfJ26FDh+jWrRtNmjShUqVKruOIiIgfBVXnLDk7cOAACQkJDBkyRPsxi4hEAHXOQW7v3r288sor1K1bl/POO891HBERCQB1zkEsISGBgwcPMmzYMHXMIiIRRJ1zkDp06BBDhw6lfv36KswiIhFGnXMQ2rZtG3v37mX06NEUL17cdRwREQkwdc5B5tSpU4wdO5arr75ahVlEJEKpcw4iGzduJD4+nuHDh7uOIiIiDqlzDhLWWqZPn85dd93lOoqIiDimzjkIrFq1ilWrVhEbG+s6ioiIBAF1zo5lZGSwZs0aHnvsMddRREQkSKhzdmjp0qUsXbqULl26uI4iIiJBRJ2zI4cPH+bkyZM8//zzrqOIiEiQUefswPz581m5ciUvvfSS6ygiIhKEVJwDbN26dVSrVo3bbrvNdRQREQlSWq0dQLNnz2b+/Pk0bNjQdRQREQli6pwDZP78+TRr1oyWLVu6jiIiIkFOnXMAzJ8/n23btlGxYkXXUUREJASoc/azqVOn0qJFC/3GLCIiPlPn7EcrV64kLS2N8uXLu44iIiIhRMXZT959910uuOAC/va3v7mOIiIiIUbF2Q9+++03zj//fKpXr+46ioiIhCAV5yL21ltvcezYMe655x7XUUREJESpOBehvXv30qhRI6688krXUUREJISpOBcBay3Dhg1j69attGjRwnUcEREJcdqVqpCstezYsYM77riDpk2buo4jIiJhQJ1zIVhr6d+/P4mJiSrMIiJSZNQ5F1BmZiYrV67kiSeeoEaNGq7jiIhIGFHnXED9+/cnKipKhVlERIqcOud8ysjI4L///S/du3cnOjradRwREQlD6pzzafTo0dSvX1+FWURE/Eads4/S0tKYNGkSL730EsYY13FERCSMqXP20UcffUSLFi1UmEVExO/UOechJSWFoUOH0q9fPxVmEREJCHXOZ5GZmcn8+fN58sknVZhFRCRgVJxzceLECV544QXuuOMOqlWr5jqOiIhEEBXnHJw8eZL169fTp08fSpQo4TqOiIhEGBXnbA4fPky3bt1o1KgRlStXdh1HREQikDYIy+LgwYPs2rWLwYMHc+6557qOIyIiEUqds9eBAwd4+eWXqVOnDuXLl3cdR0REIpg6Z2DPnj3s2bOHYcOGUbZsWddxREQkwkV853zs2DEGDRpEgwYNVJhFRCQoRHTnvH37dnbs2MHo0aMpXry46zgiIiJABHfO6enpjB07lmuvvVaFWUREgkpEds6bN29m7dq1DB061HUUERGRM0Rc52ytZfr06bRt29Z1FBERkRxFVOe8Zs0afvjhB7p27eo6ioiISK4ipnNOT09nzZo1dOzY0XUUERGRs4qIzvmnn35iwYIFxMbGuo4iIiKSp7DvnA8cOEBSUhLdunVzHUVERMQnYV2cFy1axIQJE7jlllt0PmYREQkZYVuc16xZw0UXXUSPHj1cRxEREcmXsCzO8+bN49tvv6V+/frqmEVEJOSE3QZh8+bNo3Hjxtx+++2uo4iIiBRIWHXO3333HfHx8VSqVMl1FBERkQILm875888/59Zbb6V58+auo4iIiBRKWHTO69atIykpiYoVK7qOIiIiUmghX5wnT55MdHQ0jz32mOsoIiIiRSKki3NiYiJly5albt26rqOIiIgUmZAtzmPHjiUxMZH777/fdRQREZEiFZLF+cCBA1x88cU0a9bMdRQREZEiF3LFefTo0axfv54777zTdRQRERG/CJldqay1bN++nVtuuYWmTZu6jiMiIuI3IdE5W2sZPHgwO3fuVGEWEZGwF/Sds7WWH3/8kfbt21OtWjXXcURERPwu6DvnwYMHExUVpcIsIiIRI2g758zMTKZNm0bXrl0pVaqU6zgiIiIBE7Sd89tvv02DBg1UmEVEJOL4VJyNMX82xmwyxsQbY3rkMN0YY970Tl9tjLm6oIHS0tIYM2YM//znP7n88ssL+jQiIiIhK8/ibIyJAsYAdwGXAg8bYy7NNttdQH3vpRMwtqCBpk6dSsuWLTHGFPQpREREQpovnfO1QLy1dqu1NhWYArTLNk874APrsRQob4y5KL9h5s+fz0MPPUS9evXy+1AREZGw4UtxrgbszHJ7l/e+/M6Tp6ZNm1KsWND+DC4iIhIQvmytndP6ZVuAeTDGdMKz2psqVaoQFxcHQFJSEkOHDqVq1ap/3CdF68SJExpbP9L4+o/G1r80vv5TmLH1pTjvAmpkuV0dSCzAPFhrxwPjAZo1a2ZjYmL+mNaqVSvi4uLIep8UHY2tf2l8/Udj618aX/8pzNj6sg75J6C+MaaOMaYE8BAwPds804HHvFttXw8ctdbuLlAiERGRCJdn52ytTTfGPAvMBqKASdbadcaYzt7p44CZQCsgHkgC/uG/yCIiIuHNWHvGT8OBWbAx+4Ht2e6uBBxwECcSaGz9S+PrPxpb/9L4+k9OY1vLWls5rwc6K845McYst9Y2c50jHGls/Uvj6z8aW//S+PpPYcZW+y2JiIgEGRVnERGRIBNsxXm86wBhTGPrXxpf/9HY+pfG138KPLZB9ZuziIiIBF/nLCIiEvECXpwDefrJSOTD+P7dO66rjTHfG2Mau8gZivIa2yzzXWOMyTDG3B/IfKHOl/E1xsQYY1YZY9YZYxYGOmOo8uFz4TxjzNfGmF+8Y6tjVfjIGDPJGLPPGLM2l+kFq2nW2oBd8BzEZAtQFygB/AJcmm2eVsAsPMfrvh5YFsiMoXzxcXxvBCp4r9+l8S26sc0y33w8B+a533XuULn4+N4tD6wHanpvX+A6dyhcfBzbXsAw7/XKwCGghOvsoXABbgauBtbmMr1ANS3QnXPATj8ZofIcX2vt99baw96bS/EcB13y5st7F+CfwBfAvkCGCwO+jO/fgC+ttTsArLUaY9/4MrYWKGeMMUBZPMU5PbAxQ5O1dhGe8cpNgWpaoItzwE4/GaHyO3Yd8Hyjk7zlObbGmGrAPcC4AOYKF768dxsAFYwxccaYFcaYxwKWLrT5MrZvA5fgOWHRGuB5a21mYOKFvQLVNF/OSlWUiuz0k5Ijn8fOGHMrnuLc3K+JwocvY/s60N1am+FpQCQffBnfc4CmwO1ANPCDMWaptfZXf4cLcb6MbUtgFXAbcDEw1xiz2Fp7zM/ZIkGBalqgi3ORnX5ScuTT2BljrgQmAndZaw8GKFuo82VsmwFTvIW5EtDKGJNurZ0WkIShzdfPhgPW2pPASWPMIqAxoOJ8dr6M7T+AodbzI2m8MWYb0Aj4MTARw1qBalqgV2vr9JP+lef4GmNqAl8Cj6rjyJc8x9ZaW8daW9taWxv4HPg/FWaf+fLZ8BVwkzHmHGNMaeA6YEOAc4YiX8Z2B541EhhjqgANga0BTRm+ClTTAto5W51+0q98HN+XgYrAv7wdXrrVQe/z5OPYSgH5Mr7W2g3GmG+A1UAmMNFam+PuK/I/Pr53BwCTjTFr8KyG7W6t1ZmqfGCM+QSIASoZY3YB/YDiULiapiOEiYiIBBkdIUxERCTIqDiLiIgEGRVnERGRIKPiLCIiEmRUnEVERIKMirOIiEiQUXEWEREJMirOIiIiQeb/AbAbpnb5gZTEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)             # only transform to ensure holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()                                              # only single hidden layer \n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))    # 12 node hidden layer and 8 input features\n",
    "model_1.add(Dense(1,activation='sigmoid'))                          # o/p one node that's output a value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "the reason why we have 108 parameters at that first layer is going to be we have eight input features, and then we have that fully connected to each one of the 12 nodes. If you think about that, you'd originally think maybe something like 8 times 12. But we also have that bias term, so it's going to be nine units that are actually connected. So 9 times 12 is going to give you your 108. Then to get to the next layer, again, you're going from 12 down to one, so it's going to be fully connected to that one plus the bias term so you have 12 plus that one, and that's going to be equal to 13, which is why you're going to have to learn a total of 121 different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 0.9012 - accuracy: 0.3455 - val_loss: 0.8951 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8736 - accuracy: 0.3455 - val_loss: 0.8689 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8485 - accuracy: 0.3455 - val_loss: 0.8452 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8257 - accuracy: 0.3455 - val_loss: 0.8236 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8051 - accuracy: 0.3472 - val_loss: 0.8042 - val_accuracy: 0.3594\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7865 - accuracy: 0.3490 - val_loss: 0.7866 - val_accuracy: 0.3646\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.3507 - val_loss: 0.7708 - val_accuracy: 0.3594\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.3576 - val_loss: 0.7566 - val_accuracy: 0.3490\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7408 - accuracy: 0.3646 - val_loss: 0.7437 - val_accuracy: 0.3490\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.3958 - val_loss: 0.7322 - val_accuracy: 0.3542\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.4184 - val_loss: 0.7218 - val_accuracy: 0.3646\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.4444 - val_loss: 0.7124 - val_accuracy: 0.4115\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.4740 - val_loss: 0.7040 - val_accuracy: 0.4635\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5295 - val_loss: 0.6965 - val_accuracy: 0.4740\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5573 - val_loss: 0.6897 - val_accuracy: 0.5312\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5799 - val_loss: 0.6836 - val_accuracy: 0.5729\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6128 - val_loss: 0.6781 - val_accuracy: 0.6198\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6528 - val_loss: 0.6731 - val_accuracy: 0.6094\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6580 - val_loss: 0.6686 - val_accuracy: 0.6510\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6493 - val_loss: 0.6646 - val_accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6753 - val_loss: 0.6609 - val_accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6858 - val_loss: 0.6576 - val_accuracy: 0.6823\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7049 - val_loss: 0.6546 - val_accuracy: 0.6875\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.7083 - val_loss: 0.6518 - val_accuracy: 0.6771\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7083 - val_loss: 0.6493 - val_accuracy: 0.6719\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6962 - val_loss: 0.6470 - val_accuracy: 0.6771\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6979 - val_loss: 0.6449 - val_accuracy: 0.6771\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6962 - val_loss: 0.6430 - val_accuracy: 0.6719\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6858 - val_loss: 0.6412 - val_accuracy: 0.6719\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6823 - val_loss: 0.6396 - val_accuracy: 0.6719\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6788 - val_loss: 0.6381 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6719 - val_loss: 0.6367 - val_accuracy: 0.6719\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6684 - val_loss: 0.6354 - val_accuracy: 0.6719\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6667 - val_loss: 0.6342 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6667 - val_loss: 0.6331 - val_accuracy: 0.6615\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6649 - val_loss: 0.6321 - val_accuracy: 0.6615\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6667 - val_loss: 0.6311 - val_accuracy: 0.6615\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6632 - val_loss: 0.6301 - val_accuracy: 0.6562\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6615 - val_loss: 0.6292 - val_accuracy: 0.6615\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6615 - val_loss: 0.6284 - val_accuracy: 0.6615\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6632 - val_loss: 0.6276 - val_accuracy: 0.6615\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6632 - val_loss: 0.6268 - val_accuracy: 0.6615\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6632 - val_loss: 0.6261 - val_accuracy: 0.6615\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6632 - val_loss: 0.6254 - val_accuracy: 0.6615\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6632 - val_loss: 0.6247 - val_accuracy: 0.6615\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6632 - val_loss: 0.6241 - val_accuracy: 0.6562\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6632 - val_loss: 0.6235 - val_accuracy: 0.6562\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6632 - val_loss: 0.6229 - val_accuracy: 0.6562\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6632 - val_loss: 0.6223 - val_accuracy: 0.6562\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6632 - val_loss: 0.6217 - val_accuracy: 0.6562\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6632 - val_loss: 0.6211 - val_accuracy: 0.6562\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6632 - val_loss: 0.6206 - val_accuracy: 0.6562\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6632 - val_loss: 0.6200 - val_accuracy: 0.6562\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6632 - val_loss: 0.6195 - val_accuracy: 0.6562\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6632 - val_loss: 0.6190 - val_accuracy: 0.6562\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6632 - val_loss: 0.6185 - val_accuracy: 0.6562\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6632 - val_loss: 0.6180 - val_accuracy: 0.6562\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6632 - val_loss: 0.6175 - val_accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6632 - val_loss: 0.6170 - val_accuracy: 0.6562\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6632 - val_loss: 0.6165 - val_accuracy: 0.6562\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6632 - val_loss: 0.6160 - val_accuracy: 0.6562\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6632 - val_loss: 0.6155 - val_accuracy: 0.6562\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6632 - val_loss: 0.6150 - val_accuracy: 0.6562\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6632 - val_loss: 0.6146 - val_accuracy: 0.6562\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6632 - val_loss: 0.6141 - val_accuracy: 0.6562\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6632 - val_loss: 0.6136 - val_accuracy: 0.6562\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6632 - val_loss: 0.6132 - val_accuracy: 0.6615\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6632 - val_loss: 0.6127 - val_accuracy: 0.6615\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6632 - val_loss: 0.6123 - val_accuracy: 0.6615\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6632 - val_loss: 0.6118 - val_accuracy: 0.6615\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6632 - val_loss: 0.6114 - val_accuracy: 0.6615\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6632 - val_loss: 0.6109 - val_accuracy: 0.6615\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6632 - val_loss: 0.6105 - val_accuracy: 0.6615\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6649 - val_loss: 0.6100 - val_accuracy: 0.6615\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6649 - val_loss: 0.6096 - val_accuracy: 0.6615\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6649 - val_loss: 0.6091 - val_accuracy: 0.6615\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6632 - val_loss: 0.6087 - val_accuracy: 0.6615\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6632 - val_loss: 0.6082 - val_accuracy: 0.6615\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6632 - val_loss: 0.6078 - val_accuracy: 0.6615\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6632 - val_loss: 0.6074 - val_accuracy: 0.6615\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6632 - val_loss: 0.6069 - val_accuracy: 0.6615\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6632 - val_loss: 0.6065 - val_accuracy: 0.6615\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6649 - val_loss: 0.6061 - val_accuracy: 0.6615\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6667 - val_loss: 0.6056 - val_accuracy: 0.6615\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6667 - val_loss: 0.6052 - val_accuracy: 0.6615\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6667 - val_loss: 0.6048 - val_accuracy: 0.6615\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6667 - val_loss: 0.6043 - val_accuracy: 0.6615\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6667 - val_loss: 0.6039 - val_accuracy: 0.6615\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6667 - val_loss: 0.6035 - val_accuracy: 0.6615\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6667 - val_loss: 0.6031 - val_accuracy: 0.6615\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6667 - val_loss: 0.6026 - val_accuracy: 0.6615\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6667 - val_loss: 0.6022 - val_accuracy: 0.6615\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6667 - val_loss: 0.6018 - val_accuracy: 0.6615\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6684 - val_loss: 0.6014 - val_accuracy: 0.6615\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6667 - val_loss: 0.6009 - val_accuracy: 0.6615\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6667 - val_loss: 0.6005 - val_accuracy: 0.6615\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6684 - val_loss: 0.6001 - val_accuracy: 0.6615\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6701 - val_loss: 0.5997 - val_accuracy: 0.6615\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6684 - val_loss: 0.5993 - val_accuracy: 0.6615\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6684 - val_loss: 0.5988 - val_accuracy: 0.6615\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6684 - val_loss: 0.5984 - val_accuracy: 0.6615\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6684 - val_loss: 0.5980 - val_accuracy: 0.6615\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6684 - val_loss: 0.5976 - val_accuracy: 0.6615\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6684 - val_loss: 0.5972 - val_accuracy: 0.6615\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6701 - val_loss: 0.5968 - val_accuracy: 0.6615\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6701 - val_loss: 0.5963 - val_accuracy: 0.6615\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6701 - val_loss: 0.5959 - val_accuracy: 0.6615\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6701 - val_loss: 0.5955 - val_accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6701 - val_loss: 0.5951 - val_accuracy: 0.6615\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6701 - val_loss: 0.5947 - val_accuracy: 0.6615\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6701 - val_loss: 0.5943 - val_accuracy: 0.6562\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6719 - val_loss: 0.5939 - val_accuracy: 0.6562\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6701 - val_loss: 0.5935 - val_accuracy: 0.6562\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6701 - val_loss: 0.5931 - val_accuracy: 0.6562\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6719 - val_loss: 0.5927 - val_accuracy: 0.6562\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6719 - val_loss: 0.5923 - val_accuracy: 0.6562\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6719 - val_loss: 0.5919 - val_accuracy: 0.6562\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6719 - val_loss: 0.5915 - val_accuracy: 0.6562\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6719 - val_loss: 0.5911 - val_accuracy: 0.6562\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6753 - val_loss: 0.5907 - val_accuracy: 0.6562\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6753 - val_loss: 0.5903 - val_accuracy: 0.6562\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6753 - val_loss: 0.5899 - val_accuracy: 0.6562\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.6771 - val_loss: 0.5895 - val_accuracy: 0.6562\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6771 - val_loss: 0.5891 - val_accuracy: 0.6562\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.6771 - val_loss: 0.5887 - val_accuracy: 0.6562\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6771 - val_loss: 0.5883 - val_accuracy: 0.6615\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.6771 - val_loss: 0.5879 - val_accuracy: 0.6615\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6771 - val_loss: 0.5875 - val_accuracy: 0.6615\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6771 - val_loss: 0.5871 - val_accuracy: 0.6615\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6771 - val_loss: 0.5867 - val_accuracy: 0.6615\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.6771 - val_loss: 0.5863 - val_accuracy: 0.6667\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.6771 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6771 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.6788 - val_loss: 0.5851 - val_accuracy: 0.6667\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.6806 - val_loss: 0.5847 - val_accuracy: 0.6771\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.6823 - val_loss: 0.5844 - val_accuracy: 0.6771\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6823 - val_loss: 0.5840 - val_accuracy: 0.6771\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.6823 - val_loss: 0.5836 - val_accuracy: 0.6771\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.6858 - val_loss: 0.5832 - val_accuracy: 0.6771\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6858 - val_loss: 0.5828 - val_accuracy: 0.6771\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6892 - val_loss: 0.5824 - val_accuracy: 0.6771\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6892 - val_loss: 0.5821 - val_accuracy: 0.6771\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6892 - val_loss: 0.5817 - val_accuracy: 0.6771\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.6892 - val_loss: 0.5813 - val_accuracy: 0.6823\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6892 - val_loss: 0.5809 - val_accuracy: 0.6823\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.6892 - val_loss: 0.5805 - val_accuracy: 0.6823\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6892 - val_loss: 0.5802 - val_accuracy: 0.6823\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.6910 - val_loss: 0.5798 - val_accuracy: 0.6823\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6910 - val_loss: 0.5794 - val_accuracy: 0.6875\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.6927 - val_loss: 0.5790 - val_accuracy: 0.6875\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.6944 - val_loss: 0.5787 - val_accuracy: 0.6875\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6944 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6944 - val_loss: 0.5779 - val_accuracy: 0.6927\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.6944 - val_loss: 0.5776 - val_accuracy: 0.6927\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.6944 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.6962 - val_loss: 0.5768 - val_accuracy: 0.6979\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.6979 - val_loss: 0.5764 - val_accuracy: 0.6979\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7014 - val_loss: 0.5761 - val_accuracy: 0.6979\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7031 - val_loss: 0.5757 - val_accuracy: 0.7083\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7066 - val_loss: 0.5753 - val_accuracy: 0.7083\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7049 - val_loss: 0.5750 - val_accuracy: 0.7083\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7066 - val_loss: 0.5746 - val_accuracy: 0.7135\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7083 - val_loss: 0.5743 - val_accuracy: 0.7135\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7083 - val_loss: 0.5739 - val_accuracy: 0.7135\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7083 - val_loss: 0.5735 - val_accuracy: 0.7135\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7083 - val_loss: 0.5732 - val_accuracy: 0.7135\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7101 - val_loss: 0.5728 - val_accuracy: 0.7135\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7118 - val_loss: 0.5725 - val_accuracy: 0.7135\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7118 - val_loss: 0.5721 - val_accuracy: 0.7135\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7118 - val_loss: 0.5718 - val_accuracy: 0.7135\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7118 - val_loss: 0.5714 - val_accuracy: 0.7135\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7153 - val_loss: 0.5710 - val_accuracy: 0.7135\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7135 - val_loss: 0.5707 - val_accuracy: 0.7135\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7153 - val_loss: 0.5703 - val_accuracy: 0.7135\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7205 - val_loss: 0.5700 - val_accuracy: 0.7135\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7188 - val_loss: 0.5696 - val_accuracy: 0.7188\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7188 - val_loss: 0.5693 - val_accuracy: 0.7188\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7188 - val_loss: 0.5689 - val_accuracy: 0.7188\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7188 - val_loss: 0.5686 - val_accuracy: 0.7188\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7188 - val_loss: 0.5683 - val_accuracy: 0.7240\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7188 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7188 - val_loss: 0.5676 - val_accuracy: 0.7240\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7188 - val_loss: 0.5672 - val_accuracy: 0.7240\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7205 - val_loss: 0.5669 - val_accuracy: 0.7240\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7222 - val_loss: 0.5665 - val_accuracy: 0.7240\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7222 - val_loss: 0.5662 - val_accuracy: 0.7240\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7222 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7240 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7257 - val_loss: 0.5652 - val_accuracy: 0.7292\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7257 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7274 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7274 - val_loss: 0.5642 - val_accuracy: 0.7292\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7309 - val_loss: 0.5638 - val_accuracy: 0.7292\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7309 - val_loss: 0.5635 - val_accuracy: 0.7292\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7309 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7309 - val_loss: 0.5628 - val_accuracy: 0.7292\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7326 - val_loss: 0.5625 - val_accuracy: 0.7292\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.5622 - val_accuracy: 0.7292\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7326 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7309 - val_loss: 0.5615 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 998us/step\n",
      "6/6 [==============================] - 0s 997us/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "# Note:-\n",
    "# model.predict_classes() is deprecated and will be removed after 2021-01-01.\n",
    "# Please use instead:\n",
    "#* np.argmax(model.predict(x), axis=-1), if your model does multi-class classification\n",
    "# (e.g. if it uses a softmax last-layer activation).\n",
    "#* (model.predict(x) > 0.5).astype(\"int32\"), if your model does binary classification\n",
    "# (e.g. if it uses a sigmoid last-layer activation).\n",
    "\n",
    "\n",
    "\n",
    "y_pred_class_nn_1 = (model_1.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35990828],\n",
       "       [0.3940029 ],\n",
       "       [0.31066105],\n",
       "       [0.35073432],\n",
       "       [0.26793405],\n",
       "       [0.37740186],\n",
       "       [0.23498242],\n",
       "       [0.29999247],\n",
       "       [0.65412825],\n",
       "       [0.29619503]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.734\n",
      "roc-auc is 0.790\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8h0lEQVR4nO3deXhU5fn/8c9NBFlL1AAi++panRZcS0vUYtVqUWtdaF2+ilSrXZGwKi6ALC71VxWNFq3aiKKUIqWCClFccEEjmyBhJ+xCgIRAtuf3xwx0iFkmycycWd6v68pFZuZk5jPPDHPPfc5zzjHnnAAAQOxo4HUAAABwJIozAAAxhuIMAECMoTgDABBjKM4AAMQYijMAADGG4oykY2ZNzOxNM9tjZtO8zpOszOwFMxsT+P3HZrYyxL+72cw+iGw6b9X0HM0s28wGRjMToovinODMbJ2ZFZlZgZltDXwgNq+wzHlmNs/M9gUK1ptmdkqFZb5nZn81sw2B+8oNXE6r4nHNzP5gZkvNrNDMNpnZNDP7fiSfb4iultRG0nHOuV/V987MLN3MnJk9WeH6D8zs5sDvNweWGVJhmU1mll7fDCFkDH4fbDOz5w+9D4I/6IOey/QKf39G4PrsCtebma0xs+X1yeecW+CcO7E+9xGKZCjsSAwU5+RwuXOuuSSfpB9IGn7oBjM7V9JcSf+WdIKkLpK+kvShmXUNLNNI0ruSTpV0saTvSTpP0reSzqriMR+X9EdJf5B0rKSekmZI+nltw5vZUbX9mxp0kvSNc640jFkKJd1oZp2r+fNdkoaa2fdq+7hhcuh98ENJZ0oaVcVyOySdZ2bHBV13k6RvKln2J5JaS+pqZmeGM2wii8B7GgmG4pxEnHNbJc2Rv0gfMlHSi865x51z+5xzu5xzoyQtlHRfYJkbJXWUdKVzbrlzrtw5t90596BzbnbFxzGzHpLulHS9c26ec+6gc26/c+6fzrnxgWWOWC1XsaMJdGl3mtkqSavM7Gkze7jC4/zbzP4S+P0EM3vDzHaY2Voz+0NlY2Bm90u6V9K1gS7yVjNrYGajzGy9mW03sxfNrGVg+c6BLLea2QZJ86oY3nxJL0gaXcXtkvS1pI8l/bmaZYKztgxk2RHINsrMGgRuuznQmT9sZrsDz/mSUO7XOZcn6b+STqtikWL5v0hdF3isFEnXSPpnJcveJP8Xu9mB36t7Pj8wsy8Ca2heldQ46LZ0M9sUdHmYma0OLLvczK787t3Z3wJrelaY2YVBN7Q0s7+b2RYzyzOzMWaWYmYnS3pa0rmB1z4/sPzRgXHcEFir8LSZNQnclmZms8ws38x2mdmCQ69BJc/PmX9t0Roz22lmkyq8Xh+a2WNmtkvSfdW9vjU9x0oe+xYz+zrwXphjZp0q5Pqdma0KjOeDZtbNzD42s71m9pr5v4AjhlCck4iZtZd0iaTcwOWm8nfAlW13fU1Sv8DvP5X0lnOuIMSHulDSJufcp/VLrCsknS3pFElZ8hdUkyQzO0bSRZKmBj7Q3pS/428XePw/mdnPKt6hc260pHGSXnXONXfO/V3SzYGf8yV1ldRc0hMV/rSvpJMlfec+g4yV9Eszq2717D2S/mxmx1azzCF/k9QykKmv/F+S/i/o9rMlrZSUJv+XrL8fGp/qmFkHSZdK+rKaxV4MPJ7kf87LJG2ucD9N5d9E8M/Az3VVfcgHrp8h6SX516RMk/TLah5/taQfy//875f0spm1Dbr9bElr5H/uoyVNDxrTf0gqldRd/jVFF0ka6Jz7WtLtkj4OvPapgeUnyL9mxxf4m3byf4GTpMGSNklqJf+mkBGSqjvm8ZWSesu/dqK/pFsqydxa/vdKKK9vVc/xMDO7IpDrqkDOBZJeqbDYxZJ6STpHUoakTEm/ltRB/i9p11fznOABinNymGFm+yRtlLRd/+vujpX/PbClkr/ZIv+HgiQdV8UyVant8lV5KNDJF8n/gePk/8CW/EXhY+fcZvlX0bZyzj3gnCt2zq2R9KwCnV8Ifi3pUefcmsAXkOHyF5rgVY/3OecKA1kqFVgz8bSkB6pZJkf+zQhDqwsU6FavlTQ8sEZjnaRHJN0QtNh659yzzrky+QtSW/kLSFVmBLrFDyS9J/+XlKpyfiTp2MAXjRvlL9YVXSXpYOD5zJJ0lKrebHGOpIaS/uqcK3HOvS7ps2oef5pzbnNgLc2rklbpyE0o24Pu61X5v6T83MzayP8F9E+B12u7pMdUxXsh8GXmNkl/DrzX9sk/LoeWL5F/XDsFHmuBq/6EBBMC97NB0l91ZNHb7Jz7W2BzSrFqfn0rfY6VPOZv5f+/8nXgvsdJ8gV3z4Fce51zyyQtlTQ38H7fI/9alB9U85zgAYpzcrjCOddCUrqkk/S/ortbUrn8Hz4VtZW0M/D7t1UsU5XaLl+VjYd+CXwgTtX/PuwG6H+rWTtJOiGw6jE/UIBGqPpCFewESeuDLq+Xv9AE//1GhWaCpJ+Z2RnVLHOvpDvM7PhqlkmT1KiSXO2CLm899Itzbn/g1yMm+1VwhXMu1TnXyTn3u+q+aAS8JOku+dco/KuS22+S9JpzrtQ5d1DSdFW9avsESXkVCtv6KpaVmd1oZjlBr+dp+t/7VlXc1wnyvxcaStoS9LfPyN+tVqaVpKaSFgUt/1bgekmaJP+aprmB1dXDqsocEPw+OZSpsttCeX2reo4VdZL0eFD+XZKswn1tC/q9qJLL1b1v4AGKcxJxzr0n/3bRhwOXC+XfBlrZjOVr5J8EJknvyF9wmoX4UO9Kam9mvatZplD+D8VDKitUFTuUVyRdHegIzpb0RuD6jZLWBgrPoZ8WzrlLQ8y7Wf4PuEM6yr9aNPgDLKTTtznnvpW/Y3qwmmVWyF/IRlRzVzvl79oq5soLJUeYvCTpd5JmBxV/SYc3kVwg6Tfm3wtgq/xrMy61ymfwb5HUrsJq946VPWjg9X1W/i8GxwVWPy+Vv+AcUtl9bZb/vXBQUlrQe+F7zrlTA8tVfB13yl+cTg1avmVg4pwCXe1g51xXSZdL+kt1237lX01cMdMhwY8dyutb1XOsaKOk31Z4/zcJrP1AnKI4J5+/SupnZr7A5WGSbgpMZGlhZseYf9/Tc+Xf1if5P6Q3SnrDzE4y/wSq48xshJl9pwA651ZJekrSK+af6NPIzBqb2XVBnUeOpKvMrKmZdZd0a03BnXNfyj+T+DlJc5xz+YGbPpW018yGmn8f5hQzO81Cnz38ivzbgbuYf/eiQ9ukaz2bO+BR+bfln1zNMvfLv30xtbIbA6uqX5M0NvC6dJL0F0kv1zFTrTnn1sq/LXRkJTffIP/s7RPl31brk3+77SZVvv3yY/m/8PzBzI4ys6tU9Uz/ZvIXsh2SZGb/p+9OXmsduK+GZvYr+cd6tnNui/yr2R8x/+5/DQKTn/oG/m6b/F8cGwWeY7n8XwQeM7PWgcdrd2i+gpldZmbdA0Vyr6SywE9VhgT+D3WQf2+FVytbKMTXt9LnWMndPS1puJmdGsjcMrA84hjFOck453bIv/3wnsDlD+Sf8HOV/N3Nevm3P/UJFFkFVln+VNIKSW/L/yH1qfyr5j6p4qH+IP+kqifln8m8Wv7JMm8Gbn9M/u1u2+TfXlrZTODKvBLIkhX0nMrk72p8ktbK35U8J/9km1BMkf8LyPuBvz8g6fch/u13OOf2yj9Bq8pJX4HC95L8hagqv5d/DcMa+bcTZwWyRo1z7oPAdv2KbpL0lHNua/CP/IXiO6u2nXPF8r/HbpZ/c8q18q89qOwxl8u//fVj+d8f35f0YYXFPpHUQ/7XeqykqwNrLST/NvJGkpYHHut1/W8zyzz5J7dtNbNDm22Gyr/qeqGZ7ZV/TdGhSX09ApcLAnmecs5lV5Y74N+SFsn/5fM/kv5ezbI1vb7VPcfDnHP/kn9zytRA/qXyb3dHHLPq5zYAAEJhZk5SD+dcrtdZEP/onAEAiDEUZwAAYgyrtQEAiDF0zgAAxBiKMwAAMabGM6OY2RRJl0na7pz7zoHyA/v/PS7/sXr3S7rZOfdFTfeblpbmOnfufMR1hYWFatYs1ONcoDYY28hifCOHsY0sxjdyKhvbRYsW7XTOtariTw4L5bRlL8i/v2plx9aV/PvT9Qj8nC1pcuDfanXu3Fmff/75EddlZ2crPT09hEioLcY2shjfyGFsI4vxjZzKxtbMqjxsbbAaV2s7596X/1itVekv/ykHnXNuoaTUCmePAQAAtRCOE36305EHdN8UuC4cZyUCAMShzMxMZWVl1bxgAktLS6vzWolwFOfKzh9b6f5ZZjZI0iBJatOmjbKzs4+4vaCg4DvXITwY28hifCOHsY2sSI3vU089pdzcXHXv3j3s9x0PduzYoQYNGtR5bMNRnDfpyDOxtFflZ06Rcy5T/pN8q3fv3q7iNwq2fUQOYxtZjG/kMLaRFanxTU1NVe/evZPyi9WKFSvknNO2bdvqPLbh2JVqpqQbze8cSXsCZ4YBACCpTJo0SVu3btXJJ1d3UrqahbIr1SuS0iWlmdkmSaPlP5m5nHNPy38Ks0vlP6vLfvlPgwcAQNJwzundd9/VwIEDdcwxx9T7/moszs65ys7NGny7k3RnvZMAABCnHn/8cZ177rlhKcxSeLY5AwBwxAztnJwc+Xw+bwNFQXl5uV566SX9/ve/V0pKStjul8N3AgDCIisrSzk5OZIkn8+nAQMGeBsoCl588UX5fL6wFmaJzhkAEEY+ny8pZmiXlpbqkUceUUZGhvxHsQ4vOmcAAGrprbfe0hVXXBGRwixRnAEACFlxcbGGDBmifv366cQTT4zY41CcAQAIQXFxsb744gvdeeedOvrooyP6WBRnAABqUFRUpMGDB6tnz56qeLrjSGBCGADEsEifQCI/P1+pqalhua9E3X2qsLBQq1ev1vDhw3XsscdG5THpnAEghgXvnhTrEnH3qX379ikjI0PHH3+8TjjhhKg9Lp0zAMS4SO6exIlFqpafn69169bp/vvvV1paWlQfm84ZAIAKCgsLNWLECHXs2DHqhVmicwYA4Ag7d+7UypUr9fDDD6tp06aeZKBzBgAgoKysTGPGjNHpp5/uWWGW6JwBoM4iPZNaStwZ0LFo8+bN+uSTT/TYY49F7MhfoaJzBoA6isZM6kScAR2rnn/+eV188cWeF2aJzhkA6iVZTvSQyNatW6e5c+dq5MiRXkc5jM4ZAJC0nHOaN2+ebr75Zq+jHIHOGQCQlFasWKHp06drxIgRXkf5DjpnAEDSKSws1Nq1a5WRkeF1lErROQOIKRVnQIfz2M/hxkzq+PTVV19p2rRpGjNmjNdRqkTnDCCmcCxpRNK6devknNMDDzzgdZRq0TkDiDnBM6A59jPC5dNPP9Xs2bM1evTomNhdqjp0zgCAhPfZZ5/p+OOPj4vCLFGcAQAJ7vPPP9e8efPUoUOHuCjMEsUZAJDA3nnnHZ1wwgkaOnRo3BRmieIMIAZkZmYqPT1d6enpcTMZDLFv5cqVWr58uU444QSvo9QaxRmA54JnaDMDGuHw73//W2amP/zhD15HqRNmawOICRyjGuGyfft27dixQ/379/c6Sp1RnAEACWPq1Knq3LmzBg4c6HWUemG1NgAgIezbt08pKSk655xzvI5Sb3TOAIC4N2XKFLVr106/+tWvvI4SFhRnAEBc27lzp7p06aLzzz/f6yhhQ3EGAMStJ598Up07d9bPf/5zr6OEFcUZABCXli5dqp/+9Kc68cQTvY4SdkwIAwDEnccee0xbt25NyMIs0TkDAOKIc05z587VLbfcopYtW3odJ2LonAEAceOpp55S8+bNE7owS3TOAOQ/tnVWVpZnj5+TkyOfz+fZ4yP2Oef0/PPP64477lCDBonfVyb+MwRQo+BjW3uB42mjJq+88op8Pl9SFGaJzhlAAMe2RiwqKyvTxIkTlZGRoZSUFK/jRE1yfAUBAMQd55zeffdd9e/fP6kKs0RxBgDEoJKSEmVkZOhHP/qRTjnlFK/jRB2rtQEAMaW4uFhLlizR7bffrmbNmnkdxxN0zgCAmHHgwAHdfffd6tChg7p16+Z1HM/QOQMAYsL+/fu1evVqZWRkqHXr1l7H8RSdMwDAc4WFhcrIyFCrVq3Uvn17r+N4js4ZAOCpvXv3as2aNRo9erRatWrldZyYQOcMAPDMgQMHNHz4cHXo0IHCHITOGQDgiV27dmnJkiV6+OGH1aRJE6/jxBQ6ZwBA1JWXl2vs2LHy+XwU5krQOQMxLhonpeDEE4imrVu36v3339fDDz8sM/M6TkyicwZiXDROSsGJJxBN//jHP/Tzn/+cwlwNOmcgDnBSCiSCDRs2aObMmRo6dKjXUWIenTMAIOLKy8s1f/583XbbbV5HiQt0zgCAiFq1apWysrI0evRor6PEDTpnAEDE7Nu3T+vWrdPIkSO9jhJX6JwBD9RmBjYzqRGvli5dqpdfflkPPfQQk79qic4Z8EBtZmAzkxrxaM2aNSovL9e4ceMozHVA5wx4hBnYSFSLFi3SjBkzdP/996tBA3rAumDUAABh8/nnnystLU0PPPAAhbkeGDkAQFh89dVXmjNnjjp27Miq7HqiOAMA6m3+/PlKTU3ViBEjKMxhQHEGANTL2rVr9eWXX6pTp04U5jChOAMA6uw///mPCgoK9Je//MXrKAmF4gwAqJPdu3dr06ZN+v73v+91lITDrlQAgFqbNm2aWrdurd/+9rdeR0lIdM4AgFrZv3+/JKlv374eJ0lcdM4AgJC9+OKLOuaYY/SrX/3K6ygJjeIMAAjJjh071KlTJzrmKKA4AwBq9Mwzz+j4449X//79vY6SFCjOAIBqLV68WBdeeKG6d+/udZSkwYQwAECVnnjiCW3ZsoXCHGV0zgCA73DO6b///a9uuukmtWjRwus4SYfOGQDwHc8995xatGhBYfYInTMA4DDnnJ577jndeuutnPLRQxRnoILMzExlZWXV6m/y8/OVmpoa8vI5OTny+Xy1CwZEwfTp0+Xz+SjMHmP0gQqysrKUk5MT0cfw+XwaMGBARB8DqI3y8nKNGTNGv/jFL3TmmWd6HSfphdQ5m9nFkh6XlCLpOefc+Aq3t5T0sqSOgft82Dn3fJizAlHj8/mUnZ0d8vLZ2dlKT0+PWB4gkpxzev/999W/f381bNjQ6zhQCJ2zmaVIelLSJZJOkXS9mZ1SYbE7JS13zp0hKV3SI2bWKMxZAQBhVlZWpoyMDP3gBz/g7FIxJJTV2mdJynXOrXHOFUuaKqniIWKcpBbmP8t2c0m7JJWGNSkAIKyKi4u1du1aDRo0SC1btvQ6DoKEslq7naSNQZc3STq7wjJPSJopabOkFpKudc6VV7wjMxskaZAktWnT5jurDQsKCmq1KhGhY2xDl5+fL0m1Gi/GN3IY28goLi7WM888o1/84hfKy8tTXl6e15ESTn3eu6EUZ6vkOlfh8s8k5Ui6QFI3SW+b2QLn3N4j/si5TEmZktS7d29XcRsd2+0ih7GtXvAM7XXr1snn89VqvBjfyGFsw+/AgQPKzc3VY489pjVr1jC+EVKf924oq7U3SeoQdLm9/B1ysP+TNN355UpaK+mkOiUCPBA8Q5uZ1Ehk+/fv15AhQ3TMMceoY8eOXsdBFULpnD+T1MPMukjKk3SdpIqfXBskXShpgZm1kXSipDXhDApEWm1naAPxpqCgQN98843uvfdetWrVyus4qEaNnbNzrlTSXZLmSPpa0mvOuWVmdruZ3R5Y7EFJ55nZEknvShrqnNsZqdAAgNopKSlRRkaG2rdvT2GOAyHt5+ycmy1pdoXrng76fbOki8IbDQAQDrt379bnn3+uxx57TEcffbTXcRACjhAGAAnMOaeHHnpIZ555JoU5jnBsbSSN6o6ZzbGukYi2b9+ut99+WxMmTJD/MBSIF3TOSBrVHTObGdpIRC+99JL69+9PYY5DdM5IKszIRjLIy8vTa6+9psGDB3sdBXVE5wwACaS8vFzvvfee7rjjDq+joB7onAEgQaxZs0ZTpkzRmDFjvI6CeqJzBoAEsGfPHq1fv16jR4/2OgrCgM4Zca26GdgVMSMbierrr7/WlClTNHHiRCZ/JQg6Z8S16mZgV8SMbCSi1atXq6ysTOPHj6cwJxA6Z8Q9ZmAjWS1evFhTp07VmDFj1KABvVYi4dUEgDi0aNEitWjRgsKcoHhFASDOLF++XLNnz1bnzp0pzAmKVxUA4sj777+vRo0aadSoUWxjTmAUZwCIE5s3b9Ynn3yibt26UZgTHBPCACAOzJkzR2lpaRoyZIjXURAFdM4AEOMKCgq0du1a9erVy+soiBI6ZwCIYf/617/UvHlz3X777V5HQRTROQNAjCoqKlJZWZn69evndRREGZ0zAMSgf/7zn2rSpImuvvpqr6PAAxRnxJWKx9LmeNlIRNu2bVOnTp3Up08fr6PAI6zWRlypeCxtjpeNRPPcc89pwYIFFOYkR+eMuMOxtJGovvzyS1144YXq0qWL11HgMTpnAIgBzzzzjDZv3kxhhiQ6ZwDw3MyZM/Wb3/xGzZo18zoKYgSdMwB46IUXXlDz5s0pzDgCnTMAeMA5p8zMTA0cOFApKSlex0GMoXNGzMvMzFR6errS09OPmKkNxLNZs2bp9NNPpzCjUhRnxLzg3afYdQrxrry8XGPGjFG/fv107rnneh0HMYrV2ogL7D6FROCc08KFC3XZZZepcePGXsdBDKNzBoAoKC0t1dChQ9WzZ0+Oaoca0TkDQISVlJRoxYoVuuWWW5SWluZ1HMQBOmcAiKDi4mJlZGSoZcuWOumkk7yOgzhB54yYUPGEFsE4uQXi1cGDB5Wbm6s//vGP6tixo9dxEEfonBETKp7QIhgztBGPDhw4oCFDhqhFixbq3Lmz13EQZ+icETOYkY1EUVhYqK+//lr33HOPWrVq5XUcxCE6ZwAIo7KyMg0bNkwdOnSgMKPO6JwBIEz27Nmjjz76SI888ogaNWrkdRzEMTpnAAiTSZMm6eyzz6Ywo97onAGgnnbu3KlZs2ZpzJgxXkdBgqBzBoB6ysrK0lVXXeV1DCQQOmcAqKMtW7bopZdeUkZGhtdRkGDonAGgDsrKyrRgwQLdddddXkdBAqI4A0AtrVu3TiNGjNA111yjpk2beh0HCYjiDAC1sHv3bm3YsEEPPvig11GQwNjmjKjh+NmIdytXrlRmZqYmTpyolJQUr+MggdE5I2o4fjbiWW5urkpLSzVhwgQKMyKOzhlRxfGzEY+WLVuml19+WWPGjKEwIyronAGgGl9++aUaN26ssWPHUpgRNRRnAKhCbm6uZsyYoa5du6pBAz4uET282wCgEh9++KFKSkp03333ycy8joMkQ3FGxGRmZio9Pf3wT1WTwYBYs2PHDi1YsEAnnXQShRmeoDgjYirOzmZGNuLBO++8o1WrVmnYsGEUZniG2dqIKGZnI54UFRVp1apVuuOOO7yOgiRHcQYASTNnzlSDBg0ozIgJrNYGkPSKiopUXFysyy67zOsogCQ6ZwBJburUqZKk6667zuMkwP9QnFEr1R0fuyKOl41Yt2XLFnXq1Ennnnuu11GAI7BaG7VS3fGxK2J2NmLZ888/r/fee4/CjJhE54xaYwY24t3nn3+uCy+8UB07dvQ6ClApOmcASWXKlCnKy8ujMCOm0TkDSBozZszQddddp6ZNm3odBagWnTOApDB16lQ1a9aMwoy4QOcMIKE55/TMM89o4MCBOuooPvIQH+icUaPgE1hw8grEm7lz5+q0006jMCOuUJxRo+Ddp9g9CvHCOaexY8eqT58+6tOnj9dxgFrhqyRCwu5TiCfl5eX64osvdPHFF6tZs2ZexwFqjc4ZQEIpKyvTiBEj1K5dO/Xq1cvrOECd0DkDSBilpaVatWqVbrjhBrVt29brOECd0TkDSAglJSUaOnSojj76aJ166qlexwHqhc4ZQNwrLi7WqlWrdOedd6pr165exwHqjc4ZQFwrLi7WkCFD1KxZMwozEgadM4C4VVRUpMWLF+uee+5RWlqa13GAsKFzBhCXnHMaPny4OnbsSGFGwqFzBhB39u3bp/nz52vSpElq2LCh13GAsKNzBhB3HnnkEZ133nkUZiQsOucElpmZqaysLElSfn6+UlNT63Q/OTk58vl84QsG1NGuXbv0xhtv6L777vM6ChBRIXXOZnaxma00s1wzG1bFMulmlmNmy8zsvfDGRF0EHxO7PjieNmLFq6++qmuuucbrGEDE1dg5m1mKpCcl9ZO0SdJnZjbTObc8aJlUSU9Jutg5t8HMWkcoL2rp0DGxs7OzlZ6e7nUcoE62bdumZ599VqNGjfI6ChAVoXTOZ0nKdc6tcc4VS5oqqX+FZQZImu6c2yBJzrnt4Y0JIFmVlZXpww8/1J///GevowBRE0pxbidpY9DlTYHrgvWUdIyZZZvZIjO7MVwBASSvjRs36plnntGVV17J2aWQVEKZEGaVXOcquZ9eki6U1ETSx2a20Dn3zRF3ZDZI0iBJatOmzXdOQVhQUMBpCcMoPz9fkpSdnc3YRhjjG3579uzRpk2bdN111+m995jGEim8dyOnPmMbSnHeJKlD0OX2kjZXssxO51yhpEIze1/SGZKOKM7OuUxJmZLUu3dvV3EbKNtF6yd4drYkrVu3Tj6fT+np6YxthDG+4ZWbm6sZM2bo4Ycf1gcffMDYRhDv3cipz9iGslr7M0k9zKyLmTWSdJ2kmRWW+bekH5vZUWbWVNLZkr6uUyLUWcXZ2cyyRjxavXq1Dh48qEmTJumoo9jbE8mpxne+c67UzO6SNEdSiqQpzrllZnZ74PannXNfm9lbkhZLKpf0nHNuaSSDo3KHZmcD8WjlypX6+9//rnHjxlGYkdRCevc752ZLml3huqcrXJ4kaVL4ogFIJl999ZWaNGmihx56SCkpKV7HATzF4TsBeG7Dhg2aNm2aunfvTmEGxOE7AXjsk08+UZMmTfTggw/KrLKdQ4DkQ+cMwDP5+fmaN2+evv/971OYgSB0zgA8cWji4vDhw70NAsQgOmcAUVdcXKwVK1awfy1QBTpnAFE1e/ZsHThwQLfffrvXUYCYRecMIGqKiop08OBBXXXVVV5HAWIanTOAqHj99ddVVFSkG264wesoQMyjOAOIuE2bNqljx44666yzvI4CxAWKM4CIevnll2Vm+vWvf+11FCBuUJwBRMwnn3yi888/X+3aVTwFPIDqMCEMQES89NJLysvLozADdUDnDCDs3njjDV199dVq0qSJ11GAuETnDCCspk+frmbNmlGYgXqgcwYQFs45TZ48WQMHDlSjRo28jgPENYpzDMrMzFRWVlat/y4nJ0c+ny/8gYAQvPfeezr11FMpzEAYsFo7BmVlZSknJ6fWf+fz+TRgwIDwBwKq4ZzT2LFj5fP51LdvX6/jAAmBzjlG+Xy+w2ftAWKVc06LFy9Wv379lJqa6nUcIGHQOQOok/Lyco0aNUrHHHMMR/4CwozOGUCtlZWVac2aNbr22mvVsWNHr+MACYfOGUCtlJaWatiwYXLO6fTTT/c6DpCQKM4xIjMzU+np6UpPT6/TZDAgGkpKSrRy5Urdfvvt6tmzp9dxgIRFcY4RwTO0mXWNWFRaWqqMjAw1btxY3bp18zoOkNDY5hxDmKGNWHXgwAEtWrRI99xzj4499liv4wAJj84ZQLWccxo5cqQ6depEYQaihM4ZQJUKCgo0d+5cTZgwQUcdxccFEC10zgCq9Pjjj6tPnz4UZiDK+B8H4Dvy8/OVlZWlkSNHeh0FSEp0zgC+4/XXX9f111/vdQwgadE5Azhsx44devLJJ3Xfffd5HQVIanTOACT5DzCycOFCDR482OsoQNKjOANQXl6ehgwZossuu0wtWrTwOg6Q9CjOQJLbsWOH8vLy9NBDD8nMvI4DQBRnIKmtXbtWY8aMkc/nU5MmTbyOAyCACWFAklq9erUOHjyoSZMmqVGjRl7HARCEzhlIQqtXr9bkyZPVs2dPCjMQg+icgSSzdOlSpaSkaMKECUpJSfE6DoBK0DkDSWTLli3KysrSiSeeSGEGYhidM5AkPv/8c0nS2LFjmZUNxDg6ZyAJFBYWas6cOerVqxeFGYgDdM5AgluwYIH279/PSSyAOELnDCSw0tJSLV++XBdddJHXUQDUAp0zkKDmzJmjXbt26be//a3XUQDUEp0zkID279+vAwcOcNpHIE7ROQMJZsaMGdq1a5duueUWr6MAqCOKM5BA1q9frw4dOuiKK67wOgqAeqA4R1BmZqaysrJCWjYnJ0c+ny+ygZDQXnnlFRUXF+umm27yOgqAeqI4R1BWVlbIRdfn82nAgAGRD4WE9OGHHyo9PV1t27b1OgqAMKA4R5jP51N2drbXMZDApk6dqgYNGuhHP/qR11EAhAnFGYhjr7/+uq644go1btzY6ygAwohdqYA4NWvWLB199NEUZiAB0TkDcWjy5Mm6+eab1aRJE6+jAIgAinMtMQMbXvvoo4904oknUpiBBMZq7Vo6NAM7FMzARjg55/TQQw+pR48euuCCC7yOAyCC6JzrgBnYiDbnnFasWKG+ffuqVatWXscBEGF0zkCMKy8v1+jRo9WwYUOdd955XscBEAUUZyCGlZeXa+3atbrqqqvUvXt3r+MAiBKKMxCjysrKNHz4cB08eJCJhUCSYZtzJaqbkc0MbERDaWmpVq5cqUGDBqlbt25exwEQZXTOlahuRjYzsBFp5eXlysjIUKNGjSjMQJKic64CM7LhhYMHD+qTTz7Rvffeq9TUVK/jAPAInTMQQ0aPHq3OnTtTmIEkR+cMxID9+/dr1qxZGjt2rFJSUryOA8BjdM5ADHjyySf1k5/8hMIMQBKd82HBM7SZkY1o2bt3r55//nkNGTLE6ygAYgidc0DwDG1mZCManHP617/+pd/85jdeRwEQY+icgzBDG9Hy7bff6pFHHtG4ceO8jgIgBtE5A1F28OBBffrppxo2bJjXUQDEKIozEEVbtmzR3XffrYsuukjf+973vI4DIEZRnIEo2b59u/Ly8jRhwgRmZQOoVtIW58zMTKWnpx/+qepwnUA4rF+/XmPGjNFpp52mpk2beh0HQIxL2uJc8fjZzNBGpKxdu1YFBQWaNGmSGjdu7HUcAHEgqWdrMzsbkbZ+/Xr97W9/04QJE9SwYUOv4wCIE0ldnIFI+vrrr1VWVqaJEyfqqKP4rwYgdEm7WhuIpJ07d+qFF17QySefTGEGUGt8agBh9uWXX6qoqEjjx4+XmXkdB0AcCqlzNrOLzWylmeWaWZVHTjCzM82szMyuDl9EIH4cOHBAs2fP1jnnnENhBlBnNXbOZpYi6UlJ/SRtkvSZmc10zi2vZLkJkuZEIigQ6z766CN9++23GjlypNdRAMS5UDrnsyTlOufWOOeKJU2V1L+S5X4v6Q1J28OYD4gLZWVlWrp0qS677DKvowBIAKEU53aSNgZd3hS47jAzayfpSklPhy8aEB/effddvf322xo0aBCrsgGERSgTwir7tHEVLv9V0lDnXFl1H05mNkjSIElq06bNd/YxLigoiNp+x/n5+ZKUNPs5R3Nsk0lRUZFycnLUp08fxjdCeO9GFuMbOfUZ21CK8yZJHYIut5e0ucIyvSVNDRTmNEmXmlmpc25G8ELOuUxJmZLUu3dvl56efsSdZGdnq+J1kZKamipJUXs8r0VzbJPFrFmztHnzZg0fPpzxjSDGNrIY38ipz9iGUpw/k9TDzLpIypN0naQjjnPpnOty6Hcze0HSrIqFGUgka9asUfv27dnGDCAiaizOzrlSM7tL/lnYKZKmOOeWmdntgdvZzoykMm3aNO3du1e33nqr11EAJKiQDkLinJstaXaF6yotys65m+sfC4hN77//vvr27avWrVt7HQVAAuPwnUCIpk+frs2bN1OYAUQch+8EQjBt2jRddtllatKkiddRACQBOmegBm+//bYaNmxIYQYQNXTOQDUmT56sG264Qc2bN/c6CoAkkjTFOTMzU1lZWYcv5+TkyOfzeRcIMW/RokXq1q0bhRlA1CXNau2srCzl5OQcvuzz+TRgwICq/wBJyzmniRMnqm3btrrooou8jgMgCSVN5yz5CzKHqUN1nHNavXq1zj33XJ1wwglexwGQpJKmcwZq4pzT/fffr5KSEv34xz/2Og6AJJZUnTNQlfLycq1fv16/+MUvdPLJJ3sdB0CSo3NG0isvL9fIkSO1b98+/fCHP/Q6DgDQOSO5lZWVafny5brtttvUtWtXr+MAgCQ6ZyQx55yGDRumhg0bUpgBxBQ6ZySl4uJiLViwQKNGjVLLli29jgMAR6BzRlJ64IEH1LVrVwozgJhE54ykUlRUpOnTp+uBBx5QgwZ8NwUQm/h0QlJ5+umnlZ6eTmEGENPonJEU9u3bp8zMTA0ePNjrKABQI9oHJDznnN58803deOONXkcBgJBQnJHQdu/eraFDh+r6669Xq1atvI4DACGhOCNhHThwQIsWLdKIESNkZl7HAYCQUZyRkLZt26bBgwerb9++Sk1N9ToOANQKxRkJZ/v27crLy9PEiRPVsGFDr+MAQK1RnJFQNm3apAcffFAnn3yymjVr5nUcAKgTdqVCwli/fr0KCgo0adIkNW7c2Os4AFBndM5ICJs3b9Zf//pX9ejRg8IMIO7ROSPuffPNNyoqKmIbM4CEQeeMuLZnzx4999xzOvXUUynMABIGnTPi1uLFi7Vr1y5NmDCB/ZgBJBQ6Z8SlkpISzZo1Sz/5yU8ozAASTkJ3zpmZmcrKypIk5eTkyOfzeRsIYfHpp59q48aNGjFihNdRACAiErpzzsrKUk5OjiTJ5/NpwIAB3gZCvZWXl2vx4sW66qqrvI4CABGT0J2z5C/K2dnZXsdAGGRnZ2vVqlW67bbbvI4CABGV0J0zEsfevXtVVFSkgQMHeh0FACIu4TtnxL///ve/Wr16te666y6vowBAVFCcEdNWrVql9u3b65JLLvE6CgBETUIV5+DZ2RIztOPdjBkztGPHDrYxA0g6CVWcD83OPlSQmaEdv7Kzs9WnTx+lpaV5HQUAoi6hirPE7OxE8Oabb2rPnj1KT0/3OgoAeCLhijPi26uvvqrLL79cTZs29ToKAHiGXakQM9577z0dddRRFGYASY/OGTHh6aef1rXXXqtjjjnG6ygA4Lm4KM4VZ2FXhdnZ8WnJkiXq2LEjhRkAAuJitXbwMbKrw+zs+PPII4+oefPmuvTSS72OAgAxIy46Z4lZ2InGOacNGzaoV69e6tKli9dxACCmxEXnjMTinNPYsWOVn5/P7lIAUAmKM6LKOaf169frkksu0RlnnOF1HACISRRnRE15ebnuuece7d69W7169fI6DgDErLjZ5oz4VlZWpqVLl+rWW29lGzMA1IDOGRHnnNPIkSN11FFHUZgBIAR0zoiokpISzZ8/XyNHjlSLFi28jgMAcYHOGRE1btw4de3alcIMALVA54yIOHDggF599VXdc889atCA74AAUBt8aiIipkyZogsuuIDCDAB1QOeMsCosLNQTTzyhoUOHeh0FAOIWbQ3Cxjmn2bNn6+abb/Y6CgDENYozwiI/P1+DBw/WL3/5S7Vp08brOAAQ1yjOqLeioiJ99dVXGjVqFNuYASAM+CRFvezcuVN33323zj77bB177LFexwGAhMCEMNTZjh07lJeXp/Hjx6tx48ZexwGAhEHnjDrZsmWL7r//fvXo0YMDjABAmNE5o9Y2btyo/Px8TZo0SU2aNPE6DgAkHDpn1Mr27dv18MMPq0ePHhRmAIgQOmeELDc3V3v27NGkSZPUqFEjr+MAQMKic0ZICgsLlZmZqdNPP53CDAARRueMGi1btkx5eXmaMGGCzMzrOACQ8OicUa2ysjLNnDlTF154IYUZAKKEzhlVWrRokVauXKnhw4d7HQUAkgqdMypVVlamJUuW6Prrr/c6CgAkHTpnfMcHH3ygxYsX63e/+53XUQAgKdE54wh79uzR/v37dccdd3gdBQCSFp0zDnv77be1bNky/elPf/I6CgAkNYozJEkrVqxQu3bt1K9fP6+jAEDSY7U2NGvWLM2fP1+nnHKK11EAAKJzTnrz58/Xueeeq8suu8zrKACAADrnJPbWW29p/fr1Ou6447yOAgAIQuecpF577TVdeumlat68uddRAAAV0DknoYULF0oShRkAYlRIxdnMLjazlWaWa2bDKrn912a2OPDzkZmdEf6oCIdnn31WXbt21TXXXON1FABAFWoszmaWIulJSZdIOkXS9WZWcVrvWkl9nXOnS3pQUma4g6L+vvnmGx1//PFq3bq111EAANUIpXM+S1Kuc26Nc65Y0lRJ/YMXcM595JzbHbi4UFL78MZEfb3++utyzunyyy/3OgoAoAahTAhrJ2lj0OVNks6uZvlbJf23shvMbJCkQZLUpk0bZWdnH3F7QUHBd66TpPz8fEmq9DZUzzmnb7/9Vm3bttWWLVu0ZcsWryMlpKreu6g/xjayGN/Iqc/YhlKcKzuJr6t0QbPz5S/OfSq73TmXqcAq7969e7v09PQjbs/OzlbF6yQpNTVVkiq9DVVzzmn8+PHq16+f0tLSGL8Iquq9i/pjbCOL8Y2c+oxtKKu1N0nqEHS5vaTNFRcys9MlPSepv3Pu2zqlQdg457Rhwwb169dPvXv39joOAKAWQinOn0nqYWZdzKyRpOskzQxewMw6Spou6Qbn3Dfhj4nacM5p9OjR2r59O4UZAOJQjau1nXOlZnaXpDmSUiRNcc4tM7PbA7c/LeleScdJesrMJKnUOUdV8EB5ebm++uor3XrrrerUqZPXcQAAdRDSEcKcc7Mlza5w3dNBvw+UNDC80VAXo0eP1jXXXENhBoA4xuE7E0Rpaanmzp2rYcOGqVmzZl7HAQDUA4fvTBATJ05U9+7dKcwAkADonOPcwYMH9dJLL2n48OEKbO8HAMQ5Ouc4949//EP9+vWjMANAAqFzjlP79+/Xo48+qpEjR1KYASDB0DnHIeec5s6dq1tvvZXCDAAJiOIcZ/bu3as///nPuvzyy9W2bVuv4wAAIoDiHEcKCwu1ZMkSjRo1SikpKV7HAQBECMU5TuzatUtDhgyRz+dTWlqa13EAABHEhLA4sHPnTuXl5emhhx5iP2YASAJ0zjFu27Ztuu+++9S1a1e1bNnS6zgAgCigc45heXl5+vbbbzVhwgQ6ZgBIInTOMWrXrl0aP368evToQWEGgCRD5xyD1q5dq23btunRRx9Vw4YNvY4DAIgyOucYc/DgQU2ePFk//OEPKcwAkKTonGPIihUrlJubq4kTJ3odBQDgITrnGOGc08yZM3XJJZd4HQUA4DE65xiQk5OjnJwcZWRkeB0FABAD6Jw9VlZWpiVLlujGG2/0OgoAIEbQOXto4cKFWrhwof70pz95HQUAEEPonD2ye/duFRYW6o9//KPXUQAAMYbO2QPz5s3TF198obvvvtvrKACAGERxjrJly5apXbt2uuCCC7yOAgCIUazWjqI5c+Zo3rx5OvHEE72OAgCIYXTOUTJv3jz17t1bP/vZz7yOAgCIcXTOUTBv3jytXbtWxx13nNdRAABxgM45wqZNm6Z+/fqxjRkAEDI65wj64osvVFJSotTUVK+jAADiCMU5Qv7+97+rdevWGjBggNdRAABxhuIcAevWrdOxxx6r9u3bex0FABCHKM5h9re//U179+7VlVde6XUUAECcojiH0bZt23TSSSfp9NNP9zoKACCOUZzDwDmnCRMmaM2aNerXr5/XcQAAcY5dqerJOacNGzbopz/9qXr16uV1HABAAqBzrgfnnB544AFt3ryZwgwACBs65zoqLy/XF198oVtuuUUdOnTwOg4AIIHQOdfRAw88oJSUFAozACDs6JxrqaysTP/5z380dOhQNWnSxOs4AIAEROdcS48++qh69OhBYQYARAydc4hKSko0ZcoU3X333TIzr+MAABIYnXOI/vnPf6pfv34UZgBAxMVk55yZmamsrKzDl3NycuTz+TzJcuDAAY0fP16jR4+mMAMAoiImO+esrCzl5OQcvuzz+Tw5u1N5ebnmzZun2267jcIMAIiamOycJX9Bzs7O9uzxCwoKNHLkSE2aNEmNGjXyLAcAIPnEZOfstcLCQi1fvlyjRo2iMAMAoo7iXMHu3bs1ZMgQnXTSSWrVqpXXcQAASShmV2t74dtvv9WmTZs0btw4fe973/M6DgAgSdE5B+zcuVP33nuvunTpotTUVK/jAACSWMx0zpmZmXrqqaeUmpoa9V2ntm7dqq1bt2rChAlq3rx51B4XAIDKxEznnJWVpdzcXEnR3XVq7969Gjt2rHr27ElhBgDEhJjpnCWpe/fuUd19av369dqwYYMeffRRNWzYMGqPCwBAdWKmc4620tJSTZ48WWeddRaFGQAQU2Kqc46WVatWaenSpRo/frzXUQAA+I6k65ydc5o5c6Yuv/xyr6MAAFCppOqclyxZoo8//liDBw/2OgoAAFVKms65tLRUS5Ys0cCBA72OAgBAtZKic/7ss880f/58ZWRkeB0FAIAaJXznvHPnTu3fv19DhgzxOgoAACFJ6OL8/vvv69lnn1Xfvn05HzMAIG4kbHFesmSJ2rZtq2HDhnkdBQCAWknI4vzuu+/qnXfeUY8ePeiYAQBxJ+EmhL377rs644wzdOGFF3odBQCAOkmozvmDDz5Qbm6u0tLSvI4CAECdJUzn/Prrr+v8889Xnz59vI4CAEC9JETnvGzZMu3fv1/HHXec11EAAKi3uC/OL7zwgpo0aaIbb7zR6ygAAIRFXBfnzZs3q3nz5uratavXUQAACJu4Lc6TJ0/W5s2bdfXVV3sdBQCAsIrL4rxz505169ZNvXv39joKAABhF3fF+dFHH9Xy5ct10UUXeR0FAICIiJtdqZxzWr9+vfr27atevXp5HQcAgIiJi87ZOadx48Zp48aNFGYAQMKL+c7ZOadPP/1UN998s9q1a+d1HAAAIi7mO+dx48YpJSWFwgwASBox2zmXl5drxowZGjx4sBo3bux1HAAAoiZmO+cnnnhCPXv2pDADAJJOSMXZzC42s5Vmlmtmwyq53czs/wVuX2xmP6xroJKSEj355JP6/e9/r9NOO62udwMAQNyqsTibWYqkJyVdIukUSdeb2SkVFrtEUo/AzyBJk+saaNq0afrZz34mM6vrXQAAENdC2eZ8lqRc59waSTKzqZL6S1oetEx/SS8655ykhWaWamZtnXNbQg1SXl6uLVu26LrrrlODBjG7th0AgIgLpQq2k7Qx6PKmwHW1XaZa+fn5Ou644yjMAICkF0rnXNn6ZVeHZWRmg+Rf7a02bdooOzv78G09e/ZUSUnJEdchfAoKChjbCGJ8I4exjSzGN3LqM7ahFOdNkjoEXW4vaXMdlpFzLlNSpiT17t3bpaenH74tPT1d2dnZCr4O4cPYRhbjGzmMbWQxvpFTn7ENZR3yZ5J6mFkXM2sk6TpJMyssM1PSjYFZ2+dI2lOb7c0AAOB/auycnXOlZnaXpDmSUiRNcc4tM7PbA7c/LWm2pEsl5UraL+n/IhcZAIDEZv4J1h48sNkOSesrXJ0maacHcZIBYxtZjG/kMLaRxfhGTmVj28k516qmP/SsOFfGzD53zvX2OkciYmwji/GNHMY2shjfyKnP2LLfEgAAMYbiDABAjIm14pzpdYAExthGFuMbOYxtZDG+kVPnsY2pbc4AACD2OmcAAJJe1ItzNE8/mYxCGN9fB8Z1sZl9ZGZneJEzHtU0tkHLnWlmZWZ2dTTzxbtQxtfM0s0sx8yWmdl70c4Yr0L4XGhpZm+a2VeBseVYFSEysylmtt3MllZxe91qmnMuaj/yH8RktaSukhpJ+krSKRWWuVTSf+U/Xvc5kj6JZsZ4/glxfM+TdEzg90sY3/CNbdBy8+Q/MM/VXueOl58Q37up8p8Nr2Pgcmuvc8fDT4hjO0LShMDvrSTtktTI6+zx8CPpJ5J+KGlpFbfXqaZFu3M+fPpJ51yxpEOnnwx2+PSTzrmFklLNrG2Uc8arGsfXOfeRc2534OJC+Y+DjpqF8t6VpN9LekPS9miGSwChjO8ASdOdcxskyTnHGIcmlLF1klqYmUlqLn9xLo1uzPjknHtf/vGqSp1qWrSLc1ROP5nEajt2t8r/jQ41q3FszaydpCslPR3FXIkilPduT0nHmFm2mS0ysxujli6+hTK2T0g6Wf4TFi2R9EfnXHl04iW8OtW0UM5KFU5hO/0kKhXy2JnZ+fIX5z4RTZQ4Qhnbv0oa6pwr8zcgqIVQxvcoSb0kXSipiaSPzWyhc+6bSIeLc6GM7c8k5Ui6QFI3SW+b2QLn3N4IZ0sGdapp0S7OYTv9JCoV0tiZ2emSnpN0iXPu2yhli3ehjG1vSVMDhTlN0qVmVuqcmxGVhPEt1M+Gnc65QkmFZva+pDMkUZyrF8rY/p+k8c6/kTTXzNZKOknSp9GJmNDqVNOivVqb009GVo3ja2YdJU2XdAMdR63UOLbOuS7Ouc7Ouc6SXpf0OwpzyEL5bPi3pB+b2VFm1lTS2ZK+jnLOeBTK2G6Qf42EzKyNpBMlrYlqysRVp5oW1c7ZcfrJiApxfO+VdJykpwIdXqnjoPc1CnFsUUehjK9z7msze0vSYknlkp5zzlW6+wr+J8T37oOSXjCzJfKvhh3qnONMVSEws1ckpUtKM7NNkkZLaijVr6ZxhDAAAGIMRwgDACDGUJwBAIgxFGcAAGIMxRkAgBhDcQYAIMZQnAEAiDEUZwAAYgzFGQCAGPP/AXuXLNiCwjBIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24edaab43a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7292 - val_loss: 0.5612 - val_accuracy: 0.7292\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7292 - val_loss: 0.5609 - val_accuracy: 0.7292\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7274 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7257 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7274 - val_loss: 0.5599 - val_accuracy: 0.7188\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7257 - val_loss: 0.5596 - val_accuracy: 0.7188\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7274 - val_loss: 0.5593 - val_accuracy: 0.7188\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7257 - val_loss: 0.5590 - val_accuracy: 0.7188\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7257 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7257 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7274 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7292 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7326 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7344 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7344 - val_loss: 0.5568 - val_accuracy: 0.7188\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7361 - val_loss: 0.5564 - val_accuracy: 0.7188\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7361 - val_loss: 0.5561 - val_accuracy: 0.7240\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7326 - val_loss: 0.5558 - val_accuracy: 0.7240\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7361 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7361 - val_loss: 0.5552 - val_accuracy: 0.7240\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7361 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7361 - val_loss: 0.5546 - val_accuracy: 0.7292\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7344 - val_loss: 0.5543 - val_accuracy: 0.7292\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7344 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7344 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7344 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7344 - val_loss: 0.5531 - val_accuracy: 0.7292\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7361 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7361 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7361 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7361 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7361 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7378 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7413 - val_loss: 0.5510 - val_accuracy: 0.7240\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7413 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7413 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7413 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7413 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7413 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7396 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7396 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7396 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7396 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7396 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7396 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7378 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7378 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7361 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7361 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7361 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7378 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7378 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7396 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7396 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7396 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7396 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7396 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7448 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7465 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7448 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7448 - val_loss: 0.5435 - val_accuracy: 0.7448\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7448 - val_loss: 0.5432 - val_accuracy: 0.7448\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7448 - val_loss: 0.5430 - val_accuracy: 0.7448\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7448 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7448 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7448 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7465 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7465 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7465 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7465 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7465 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7465 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7448 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7448 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7448 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7448 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7448 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7448 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7448 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7465 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7465 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7465 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7448 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7483 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.5369 - val_accuracy: 0.7448\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7517 - val_loss: 0.5367 - val_accuracy: 0.7448\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7500 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7500 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7483 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7500 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7552 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7552 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7552 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7552 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7552 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7552 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7552 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7569 - val_loss: 0.5332 - val_accuracy: 0.7500\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7569 - val_loss: 0.5330 - val_accuracy: 0.7500\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7552 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7569 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7569 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7569 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7569 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7569 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7569 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7569 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7569 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7569 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7569 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7569 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7569 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7569 - val_loss: 0.5299 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7569 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7569 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7569 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7569 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7569 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7569 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7587 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7569 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7587 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7587 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7587 - val_loss: 0.5271 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7587 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7587 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7587 - val_loss: 0.5265 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7569 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7587 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7587 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7587 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7587 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7587 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7604 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7604 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7604 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7587 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7587 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7604 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7587 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7587 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7587 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7587 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7604 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7622 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7622 - val_loss: 0.5199 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7622 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7622 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7622 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7622 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7622 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7622 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7622 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7639 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7639 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7639 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7639 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7639 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7639 - val_loss: 0.5171 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5169 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7639 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7639 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7639 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7639 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7639 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7656 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7656 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7656 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7656 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7674 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7691 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7691 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7708 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7708 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7691 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7691 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7691 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7674 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5116 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7674 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7674 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7674 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7674 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7708 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7708 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7708 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7726 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7726 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7726 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7726 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7726 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7726 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7726 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7726 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7726 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7726 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7743 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7743 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5060 - val_accuracy: 0.7552\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7743 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7760 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7778 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7778 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7760 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7760 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7760 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7760 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7760 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7760 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7795 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7760 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7760 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7778 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7760 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7760 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7778 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7778 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7778 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4973 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7778 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24edbb94c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7837 - accuracy: 0.4340 - val_loss: 0.7611 - val_accuracy: 0.4688\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7704 - accuracy: 0.4462 - val_loss: 0.7483 - val_accuracy: 0.4688\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7586 - accuracy: 0.4740 - val_loss: 0.7367 - val_accuracy: 0.4896\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.4913 - val_loss: 0.7264 - val_accuracy: 0.4948\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7383 - accuracy: 0.5122 - val_loss: 0.7172 - val_accuracy: 0.4948\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.5243 - val_loss: 0.7088 - val_accuracy: 0.5156\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.5347 - val_loss: 0.7015 - val_accuracy: 0.5365\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7145 - accuracy: 0.5556 - val_loss: 0.6949 - val_accuracy: 0.5417\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.5694 - val_loss: 0.6888 - val_accuracy: 0.5469\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.5747 - val_loss: 0.6832 - val_accuracy: 0.5573\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5747 - val_loss: 0.6780 - val_accuracy: 0.5729\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5868 - val_loss: 0.6733 - val_accuracy: 0.5990\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5972 - val_loss: 0.6689 - val_accuracy: 0.6302\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6076 - val_loss: 0.6650 - val_accuracy: 0.6198\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6146 - val_loss: 0.6613 - val_accuracy: 0.6354\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.6233 - val_loss: 0.6579 - val_accuracy: 0.6354\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6285 - val_loss: 0.6546 - val_accuracy: 0.6458\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6354 - val_loss: 0.6515 - val_accuracy: 0.6615\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6441 - val_loss: 0.6486 - val_accuracy: 0.6667\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6406 - val_loss: 0.6459 - val_accuracy: 0.6667\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6545 - val_loss: 0.6434 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6597 - val_loss: 0.6409 - val_accuracy: 0.6823\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6719 - val_loss: 0.6386 - val_accuracy: 0.6875\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6736 - val_loss: 0.6364 - val_accuracy: 0.6979\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6823 - val_loss: 0.6342 - val_accuracy: 0.6979\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6823 - val_loss: 0.6321 - val_accuracy: 0.6875\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6823 - val_loss: 0.6301 - val_accuracy: 0.6875\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6858 - val_loss: 0.6282 - val_accuracy: 0.6979\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6979 - val_loss: 0.6263 - val_accuracy: 0.7083\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6997 - val_loss: 0.6245 - val_accuracy: 0.7031\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6997 - val_loss: 0.6228 - val_accuracy: 0.7083\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7014 - val_loss: 0.6211 - val_accuracy: 0.7083\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.7014 - val_loss: 0.6196 - val_accuracy: 0.7083\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.7031 - val_loss: 0.6180 - val_accuracy: 0.7188\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.7066 - val_loss: 0.6165 - val_accuracy: 0.7240\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7083 - val_loss: 0.6150 - val_accuracy: 0.7292\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.7101 - val_loss: 0.6136 - val_accuracy: 0.7292\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7135 - val_loss: 0.6123 - val_accuracy: 0.7292\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7170 - val_loss: 0.6109 - val_accuracy: 0.7292\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7153 - val_loss: 0.6096 - val_accuracy: 0.7292\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.7153 - val_loss: 0.6083 - val_accuracy: 0.7344\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7153 - val_loss: 0.6071 - val_accuracy: 0.7344\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7153 - val_loss: 0.6059 - val_accuracy: 0.7396\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7153 - val_loss: 0.6047 - val_accuracy: 0.7396\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.7153 - val_loss: 0.6035 - val_accuracy: 0.7396\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7153 - val_loss: 0.6024 - val_accuracy: 0.7448\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7188 - val_loss: 0.6012 - val_accuracy: 0.7448\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.7170 - val_loss: 0.6001 - val_accuracy: 0.7448\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7188 - val_loss: 0.5990 - val_accuracy: 0.7448\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.7188 - val_loss: 0.5979 - val_accuracy: 0.7448\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7188 - val_loss: 0.5969 - val_accuracy: 0.7448\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7188 - val_loss: 0.5958 - val_accuracy: 0.7448\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7240 - val_loss: 0.5948 - val_accuracy: 0.7448\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7240 - val_loss: 0.5938 - val_accuracy: 0.7500\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7274 - val_loss: 0.5927 - val_accuracy: 0.7500\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7309 - val_loss: 0.5918 - val_accuracy: 0.7552\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7274 - val_loss: 0.5908 - val_accuracy: 0.7552\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7274 - val_loss: 0.5899 - val_accuracy: 0.7552\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7274 - val_loss: 0.5889 - val_accuracy: 0.7552\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7274 - val_loss: 0.5880 - val_accuracy: 0.7552\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7274 - val_loss: 0.5871 - val_accuracy: 0.7552\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7274 - val_loss: 0.5862 - val_accuracy: 0.7552\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7292 - val_loss: 0.5854 - val_accuracy: 0.7552\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7292 - val_loss: 0.5845 - val_accuracy: 0.7552\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7292 - val_loss: 0.5836 - val_accuracy: 0.7552\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7292 - val_loss: 0.5827 - val_accuracy: 0.7604\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7309 - val_loss: 0.5819 - val_accuracy: 0.7656\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7292 - val_loss: 0.5810 - val_accuracy: 0.7656\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7292 - val_loss: 0.5802 - val_accuracy: 0.7656\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7274 - val_loss: 0.5794 - val_accuracy: 0.7656\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7326 - val_loss: 0.5786 - val_accuracy: 0.7656\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7326 - val_loss: 0.5778 - val_accuracy: 0.7656\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7326 - val_loss: 0.5770 - val_accuracy: 0.7656\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7326 - val_loss: 0.5762 - val_accuracy: 0.7656\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7344 - val_loss: 0.5755 - val_accuracy: 0.7656\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7344 - val_loss: 0.5747 - val_accuracy: 0.7656\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7378 - val_loss: 0.5739 - val_accuracy: 0.7656\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7396 - val_loss: 0.5732 - val_accuracy: 0.7656\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7396 - val_loss: 0.5724 - val_accuracy: 0.7656\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7396 - val_loss: 0.5717 - val_accuracy: 0.7656\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7396 - val_loss: 0.5709 - val_accuracy: 0.7656\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7396 - val_loss: 0.5702 - val_accuracy: 0.7656\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7396 - val_loss: 0.5694 - val_accuracy: 0.7656\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7396 - val_loss: 0.5687 - val_accuracy: 0.7656\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7396 - val_loss: 0.5680 - val_accuracy: 0.7656\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7396 - val_loss: 0.5673 - val_accuracy: 0.7656\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7396 - val_loss: 0.5666 - val_accuracy: 0.7656\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7396 - val_loss: 0.5659 - val_accuracy: 0.7656\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7396 - val_loss: 0.5652 - val_accuracy: 0.7656\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7396 - val_loss: 0.5645 - val_accuracy: 0.7656\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7396 - val_loss: 0.5639 - val_accuracy: 0.7656\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7396 - val_loss: 0.5632 - val_accuracy: 0.7656\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7413 - val_loss: 0.5626 - val_accuracy: 0.7656\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7413 - val_loss: 0.5619 - val_accuracy: 0.7656\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7413 - val_loss: 0.5613 - val_accuracy: 0.7656\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7396 - val_loss: 0.5607 - val_accuracy: 0.7656\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7396 - val_loss: 0.5601 - val_accuracy: 0.7656\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7396 - val_loss: 0.5594 - val_accuracy: 0.7656\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7396 - val_loss: 0.5588 - val_accuracy: 0.7656\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7396 - val_loss: 0.5582 - val_accuracy: 0.7656\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7396 - val_loss: 0.5576 - val_accuracy: 0.7656\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7396 - val_loss: 0.5570 - val_accuracy: 0.7656\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7396 - val_loss: 0.5565 - val_accuracy: 0.7656\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7396 - val_loss: 0.5559 - val_accuracy: 0.7656\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7396 - val_loss: 0.5553 - val_accuracy: 0.7656\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7396 - val_loss: 0.5548 - val_accuracy: 0.7656\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.7656\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7396 - val_loss: 0.5537 - val_accuracy: 0.7656\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7396 - val_loss: 0.5531 - val_accuracy: 0.7656\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7396 - val_loss: 0.5526 - val_accuracy: 0.7604\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7396 - val_loss: 0.5520 - val_accuracy: 0.7604\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7396 - val_loss: 0.5515 - val_accuracy: 0.7604\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7378 - val_loss: 0.5510 - val_accuracy: 0.7604\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7378 - val_loss: 0.5505 - val_accuracy: 0.7604\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7396 - val_loss: 0.5500 - val_accuracy: 0.7604\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7396 - val_loss: 0.5494 - val_accuracy: 0.7604\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7396 - val_loss: 0.5490 - val_accuracy: 0.7604\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7396 - val_loss: 0.5485 - val_accuracy: 0.7604\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7396 - val_loss: 0.5480 - val_accuracy: 0.7604\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7396 - val_loss: 0.5475 - val_accuracy: 0.7604\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7413 - val_loss: 0.5470 - val_accuracy: 0.7604\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7396 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7396 - val_loss: 0.5460 - val_accuracy: 0.7604\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.7431 - val_loss: 0.5456 - val_accuracy: 0.7604\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7413 - val_loss: 0.5451 - val_accuracy: 0.7604\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7413 - val_loss: 0.5447 - val_accuracy: 0.7604\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7413 - val_loss: 0.5442 - val_accuracy: 0.7604\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7413 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7413 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7431 - val_loss: 0.5429 - val_accuracy: 0.7604\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7431 - val_loss: 0.5425 - val_accuracy: 0.7604\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7448 - val_loss: 0.5420 - val_accuracy: 0.7604\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7465 - val_loss: 0.5416 - val_accuracy: 0.7604\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7465 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7448 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7465 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7465 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7465 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7465 - val_loss: 0.5387 - val_accuracy: 0.7552\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7465 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7465 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7465 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7465 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7465 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7483 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7483 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7500 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7483 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7500 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7500 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7483 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7604\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7500 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7500 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7500 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7500 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7500 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7517 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7500 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7517 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7517 - val_loss: 0.5298 - val_accuracy: 0.7604\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7517 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7500 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7535 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7535 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7517 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7552 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7535 - val_loss: 0.5270 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7535 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7535 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7535 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7535 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7535 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7535 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7535 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7552 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7535 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7552 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7569 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7569 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7587 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7587 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7604 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7604 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7587 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7587 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7587 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7587 - val_loss: 0.5197 - val_accuracy: 0.7656\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7587 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7587 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7587 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7587 - val_loss: 0.5182 - val_accuracy: 0.7656\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7552 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7569 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7552 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7569 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7569 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7569 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7569 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7569 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7622 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7604 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7622 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7622 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7622 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7622 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7622 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7622 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7639 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7656 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7639 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7639 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7656 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7656 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7656 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7656 - val_loss: 0.5115 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7656 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7656 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7656 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7656 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7656 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7656 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7656 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7656 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7656 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7656 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7674 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7656 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7691 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7691 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7691 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7708 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7708 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7708 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7708 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7708 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7708 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7708 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7708 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7743 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7743 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7726 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7743 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7743 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7743 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7743 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7760 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7743 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7760 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7760 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7760 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7760 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7760 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7760 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7760 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7760 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7760 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7760 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7760 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7743 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7778 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7760 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7760 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7760\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7760 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7760 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7760 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7812\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.7812\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7760 - val_loss: 0.4894 - val_accuracy: 0.7812\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7812\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7778 - val_loss: 0.4892 - val_accuracy: 0.7812\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7812\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7812\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7760 - val_loss: 0.4885 - val_accuracy: 0.7812\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7760 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7795 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7812\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7812\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7795 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7795 - val_loss: 0.4872 - val_accuracy: 0.7812\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7795 - val_loss: 0.4871 - val_accuracy: 0.7812\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7812\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7812\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7812\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7812\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7812\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7795 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7760\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7760\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7830 - val_loss: 0.4853 - val_accuracy: 0.7760\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7830 - val_loss: 0.4852 - val_accuracy: 0.7760\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.4851 - val_accuracy: 0.7760\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.4850 - val_accuracy: 0.7760\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7795 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.4849 - val_accuracy: 0.7760\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7830 - val_loss: 0.4848 - val_accuracy: 0.7760\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.4847 - val_accuracy: 0.7760\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7795 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7812 - val_loss: 0.4846 - val_accuracy: 0.7760\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7760\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7830 - val_loss: 0.4845 - val_accuracy: 0.7760\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7830 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7830 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7830 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7830 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7830 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7830 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7830 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7830 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7830 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4837 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7847 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7847 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7865 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7865 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7865 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7865 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7865 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7865 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7865 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7865 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7865 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7865 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7847 - val_loss: 0.4823 - val_accuracy: 0.7604\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7865 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7865 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7865 - val_loss: 0.4821 - val_accuracy: 0.7708\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7865 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7865 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7865 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7847 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7865 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7865 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7847 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.4812 - val_accuracy: 0.7708\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.4811 - val_accuracy: 0.7708\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7882 - val_loss: 0.4810 - val_accuracy: 0.7708\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.4809 - val_accuracy: 0.7656\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7656\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7882 - val_loss: 0.4808 - val_accuracy: 0.7656\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7882 - val_loss: 0.4808 - val_accuracy: 0.7656\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7882 - val_loss: 0.4808 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7656\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7656\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7656\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7656\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7882 - val_loss: 0.4805 - val_accuracy: 0.7656\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.4805 - val_accuracy: 0.7656\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.4804 - val_accuracy: 0.7656\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.4804 - val_accuracy: 0.7656\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7656\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7656\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7656\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7656\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7882 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7708\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7708\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.4797 - val_accuracy: 0.7708\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4798 - val_accuracy: 0.7708\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.4800 - val_accuracy: 0.7708\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7656\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.4800 - val_accuracy: 0.7656\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7604\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.4800 - val_accuracy: 0.7604\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7604\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7604\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7604\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7604\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.4801 - val_accuracy: 0.7656\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.4802 - val_accuracy: 0.7656\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7865 - val_loss: 0.4803 - val_accuracy: 0.7604\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4804 - val_accuracy: 0.7552\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4804 - val_accuracy: 0.7552\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4805 - val_accuracy: 0.7552\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4805 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.4805 - val_accuracy: 0.7552\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.4805 - val_accuracy: 0.7552\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4805 - val_accuracy: 0.7552\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4805 - val_accuracy: 0.7552\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.4807 - val_accuracy: 0.7552\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7552\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7899 - val_loss: 0.4809 - val_accuracy: 0.7552\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7899 - val_loss: 0.4810 - val_accuracy: 0.7500\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4810 - val_accuracy: 0.7500\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4810 - val_accuracy: 0.7500\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7899 - val_loss: 0.4810 - val_accuracy: 0.7500\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4810 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4811 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7899 - val_loss: 0.4811 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.4811 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4811 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4811 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.4811 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.4812 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4813 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4814 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4815 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4815 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4815 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4815 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4815 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7899 - val_loss: 0.4816 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.4817 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4819 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4819 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4819 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4819 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.4820 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4820 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.4820 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4820 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4820 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4821 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.4821 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4821 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4822 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7917 - val_loss: 0.4823 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7934 - val_loss: 0.4823 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7917 - val_loss: 0.4823 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.4823 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.4824 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.4824 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.4824 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.4824 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.4825 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4825 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4825 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7917 - val_loss: 0.4826 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.4827 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.4827 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.4828 - val_accuracy: 0.7500\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4831 - val_accuracy: 0.7500\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.4831 - val_accuracy: 0.7500\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.4831 - val_accuracy: 0.7500\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4832 - val_accuracy: 0.7500\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4832 - val_accuracy: 0.7500\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4832 - val_accuracy: 0.7500\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4832 - val_accuracy: 0.7500\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7500\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7500\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7500\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4833 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4834 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7934 - val_loss: 0.4834 - val_accuracy: 0.7552\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.4834 - val_accuracy: 0.7552\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.4834 - val_accuracy: 0.7552\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4834 - val_accuracy: 0.7500\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.4834 - val_accuracy: 0.7552\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.4834 - val_accuracy: 0.7552\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7552\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7552\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.4835 - val_accuracy: 0.7552\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4835 - val_accuracy: 0.7552\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4836 - val_accuracy: 0.7552\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4837 - val_accuracy: 0.7552\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.4838 - val_accuracy: 0.7552\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.4839 - val_accuracy: 0.7552\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7951 - val_loss: 0.4839 - val_accuracy: 0.7552\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4840 - val_accuracy: 0.7552\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4841 - val_accuracy: 0.7552\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4841 - val_accuracy: 0.7552\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.4841 - val_accuracy: 0.7552\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.4843 - val_accuracy: 0.7552\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.4844 - val_accuracy: 0.7552\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.4844 - val_accuracy: 0.7552\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.4844 - val_accuracy: 0.7552\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.4844 - val_accuracy: 0.7552\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7552\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7552\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.4846 - val_accuracy: 0.7552\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.4847 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.4847 - val_accuracy: 0.7500\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.4857 - val_accuracy: 0.7552\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.4858 - val_accuracy: 0.7552\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.4858 - val_accuracy: 0.7552\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.4858 - val_accuracy: 0.7552\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.4859 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.4867 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4867 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4867 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4868 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.4868 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4868 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4869 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4869 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4869 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4870 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4870 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4870 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4871 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4871 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4871 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.4872 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4872 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.4872 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.4872 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.4873 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7969 - val_loss: 0.4873 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4873 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4873 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4874 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4874 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4874 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4874 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.4874 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4874 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4875 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4875 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4875 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4875 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4876 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4877 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4877 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4877 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4878 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4878 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4878 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4878 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4879 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4879 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4879 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4879 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4881 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4881 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4881 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4884 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4884 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4884 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8003 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7448\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7448\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7448\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7448\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.4907 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.4908 - val_accuracy: 0.7448\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.4909 - val_accuracy: 0.7448\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8038 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8038 - val_loss: 0.4910 - val_accuracy: 0.7448\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4911 - val_accuracy: 0.7448\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.4913 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.4914 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8003 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8003 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8003 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8021 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8021 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8021 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8003 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8021 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8021 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8021 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8021 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8021 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8021 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8021 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8021 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8021 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8021 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8021 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8038 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8021 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8038 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8038 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8021 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8038 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8021 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8021 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 798us/step\n",
      "6/6 [==============================] - 0s 997us/step\n",
      "\n",
      "accuracy is 0.745\n",
      "roc-auc is 0.812\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = (model_2.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
